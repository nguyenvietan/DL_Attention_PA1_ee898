{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50_attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenvietan/DL_Attention_PA1_ee898/blob/master/resnet50_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZV_D6rK4Phj",
        "colab_type": "code",
        "outputId": "aa98e41e-f4e8-48e2-f553-eaf999d21c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7281
        }
      },
      "source": [
        "!bash run_all_50.sh\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(arch='resnet50', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 4.760 | top1-e-train: 0.965, top5-e-train: 0.857 | top1-e-test: 0.966, top5-e-test: 0.851\n",
            "[Epoch   1], lr: 0.10000, Loss: 4.156 | top1-e-train: 0.930, top5-e-train: 0.748 | top1-e-test: 0.927, top5-e-test: 0.741\n",
            "[Epoch   2], lr: 0.10000, Loss: 3.831 | top1-e-train: 0.880, top5-e-train: 0.641 | top1-e-test: 0.877, top5-e-test: 0.633\n",
            "[Epoch   3], lr: 0.10000, Loss: 3.539 | top1-e-train: 0.824, top5-e-train: 0.536 | top1-e-test: 0.815, top5-e-test: 0.528\n",
            "[Epoch   4], lr: 0.10000, Loss: 3.236 | top1-e-train: 0.761, top5-e-train: 0.456 | top1-e-test: 0.758, top5-e-test: 0.452\n",
            "[Epoch   5], lr: 0.10000, Loss: 3.005 | top1-e-train: 0.720, top5-e-train: 0.404 | top1-e-test: 0.718, top5-e-test: 0.406\n",
            "[Epoch   6], lr: 0.10000, Loss: 2.789 | top1-e-train: 0.679, top5-e-train: 0.361 | top1-e-test: 0.679, top5-e-test: 0.372\n",
            "[Epoch   7], lr: 0.10000, Loss: 2.592 | top1-e-train: 0.641, top5-e-train: 0.316 | top1-e-test: 0.645, top5-e-test: 0.323\n",
            "[Epoch   8], lr: 0.10000, Loss: 2.414 | top1-e-train: 0.599, top5-e-train: 0.273 | top1-e-test: 0.606, top5-e-test: 0.285\n",
            "[Epoch   9], lr: 0.10000, Loss: 2.260 | top1-e-train: 0.568, top5-e-train: 0.245 | top1-e-test: 0.585, top5-e-test: 0.271\n",
            "[Epoch  10], lr: 0.10000, Loss: 2.139 | top1-e-train: 0.543, top5-e-train: 0.222 | top1-e-test: 0.564, top5-e-test: 0.251\n",
            "[Epoch  11], lr: 0.10000, Loss: 2.007 | top1-e-train: 0.528, top5-e-train: 0.213 | top1-e-test: 0.559, top5-e-test: 0.246\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.905 | top1-e-train: 0.485, top5-e-train: 0.178 | top1-e-test: 0.525, top5-e-test: 0.224\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.806 | top1-e-train: 0.479, top5-e-train: 0.180 | top1-e-test: 0.522, top5-e-test: 0.229\n",
            "[Epoch  14], lr: 0.10000, Loss: 1.717 | top1-e-train: 0.451, top5-e-train: 0.154 | top1-e-test: 0.508, top5-e-test: 0.208\n",
            "[Epoch  15], lr: 0.10000, Loss: 1.634 | top1-e-train: 0.425, top5-e-train: 0.138 | top1-e-test: 0.494, top5-e-test: 0.201\n",
            "[Epoch  16], lr: 0.10000, Loss: 1.556 | top1-e-train: 0.415, top5-e-train: 0.127 | top1-e-test: 0.498, top5-e-test: 0.196\n",
            "[Epoch  17], lr: 0.10000, Loss: 1.479 | top1-e-train: 0.403, top5-e-train: 0.119 | top1-e-test: 0.486, top5-e-test: 0.194\n",
            "[Epoch  18], lr: 0.10000, Loss: 1.401 | top1-e-train: 0.376, top5-e-train: 0.107 | top1-e-test: 0.476, top5-e-test: 0.186\n",
            "[Epoch  19], lr: 0.10000, Loss: 1.360 | top1-e-train: 0.367, top5-e-train: 0.099 | top1-e-test: 0.465, top5-e-test: 0.180\n",
            "[Epoch  20], lr: 0.10000, Loss: 1.298 | top1-e-train: 0.340, top5-e-train: 0.086 | top1-e-test: 0.455, top5-e-test: 0.178\n",
            "[Epoch  21], lr: 0.10000, Loss: 1.224 | top1-e-train: 0.322, top5-e-train: 0.077 | top1-e-test: 0.459, top5-e-test: 0.175\n",
            "[Epoch  22], lr: 0.10000, Loss: 1.143 | top1-e-train: 0.311, top5-e-train: 0.071 | top1-e-test: 0.455, top5-e-test: 0.176\n",
            "[Epoch  23], lr: 0.10000, Loss: 1.087 | top1-e-train: 0.299, top5-e-train: 0.065 | top1-e-test: 0.455, top5-e-test: 0.173\n",
            "[Epoch  24], lr: 0.10000, Loss: 1.021 | top1-e-train: 0.271, top5-e-train: 0.054 | top1-e-test: 0.434, top5-e-test: 0.170\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.960 | top1-e-train: 0.254, top5-e-train: 0.049 | top1-e-test: 0.440, top5-e-test: 0.163\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.906 | top1-e-train: 0.247, top5-e-train: 0.042 | top1-e-test: 0.444, top5-e-test: 0.163\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.854 | top1-e-train: 0.235, top5-e-train: 0.041 | top1-e-test: 0.442, top5-e-test: 0.169\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.798 | top1-e-train: 0.210, top5-e-train: 0.033 | top1-e-test: 0.423, top5-e-test: 0.154\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.513 | top1-e-train: 0.120, top5-e-train: 0.017 | top1-e-test: 0.390, top5-e-test: 0.146\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.408 | top1-e-train: 0.101, top5-e-train: 0.012 | top1-e-test: 0.386, top5-e-test: 0.142\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.359 | top1-e-train: 0.089, top5-e-train: 0.010 | top1-e-test: 0.381, top5-e-test: 0.138\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.327 | top1-e-train: 0.085, top5-e-train: 0.011 | top1-e-test: 0.382, top5-e-test: 0.141\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.302 | top1-e-train: 0.077, top5-e-train: 0.008 | top1-e-test: 0.387, top5-e-test: 0.141\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.283 | top1-e-train: 0.070, top5-e-train: 0.008 | top1-e-test: 0.390, top5-e-test: 0.145\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.275 | top1-e-train: 0.065, top5-e-train: 0.009 | top1-e-test: 0.388, top5-e-test: 0.143\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.244 | top1-e-train: 0.058, top5-e-train: 0.006 | top1-e-test: 0.391, top5-e-test: 0.140\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.223 | top1-e-train: 0.055, top5-e-train: 0.006 | top1-e-test: 0.386, top5-e-test: 0.143\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.209 | top1-e-train: 0.051, top5-e-train: 0.007 | top1-e-test: 0.388, top5-e-test: 0.141\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.195 | top1-e-train: 0.044, top5-e-train: 0.005 | top1-e-test: 0.387, top5-e-test: 0.141\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.184 | top1-e-train: 0.044, top5-e-train: 0.006 | top1-e-test: 0.391, top5-e-test: 0.140\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.176 | top1-e-train: 0.043, top5-e-train: 0.006 | top1-e-test: 0.391, top5-e-test: 0.141\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.169 | top1-e-train: 0.039, top5-e-train: 0.006 | top1-e-test: 0.391, top5-e-test: 0.143\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.155 | top1-e-train: 0.038, top5-e-train: 0.007 | top1-e-test: 0.396, top5-e-test: 0.147\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.147 | top1-e-train: 0.032, top5-e-train: 0.004 | top1-e-test: 0.391, top5-e-test: 0.144\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.140 | top1-e-train: 0.031, top5-e-train: 0.003 | top1-e-test: 0.391, top5-e-test: 0.143\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.137 | top1-e-train: 0.031, top5-e-train: 0.006 | top1-e-test: 0.389, top5-e-test: 0.145\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.128 | top1-e-train: 0.028, top5-e-train: 0.005 | top1-e-test: 0.394, top5-e-test: 0.146\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.116 | top1-e-train: 0.025, top5-e-train: 0.004 | top1-e-test: 0.388, top5-e-test: 0.142\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.114 | top1-e-train: 0.024, top5-e-train: 0.004 | top1-e-test: 0.393, top5-e-test: 0.144\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.108 | top1-e-train: 0.025, top5-e-train: 0.005 | top1-e-test: 0.393, top5-e-test: 0.143\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.102 | top1-e-train: 0.023, top5-e-train: 0.005 | top1-e-test: 0.394, top5-e-test: 0.144\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.094 | top1-e-train: 0.022, top5-e-train: 0.004 | top1-e-test: 0.395, top5-e-test: 0.145\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.093 | top1-e-train: 0.022, top5-e-train: 0.005 | top1-e-test: 0.393, top5-e-test: 0.143\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.087 | top1-e-train: 0.021, top5-e-train: 0.005 | top1-e-test: 0.393, top5-e-test: 0.146\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.082 | top1-e-train: 0.020, top5-e-train: 0.006 | top1-e-test: 0.399, top5-e-test: 0.148\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.080 | top1-e-train: 0.018, top5-e-train: 0.004 | top1-e-test: 0.393, top5-e-test: 0.146\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.076 | top1-e-train: 0.015, top5-e-train: 0.003 | top1-e-test: 0.394, top5-e-test: 0.145\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.071 | top1-e-train: 0.018, top5-e-train: 0.006 | top1-e-test: 0.393, top5-e-test: 0.145\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.062 | top1-e-train: 0.013, top5-e-train: 0.004 | top1-e-test: 0.387, top5-e-test: 0.141\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.058 | top1-e-train: 0.015, top5-e-train: 0.006 | top1-e-test: 0.390, top5-e-test: 0.143\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.057 | top1-e-train: 0.015, top5-e-train: 0.007 | top1-e-test: 0.390, top5-e-test: 0.144\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.052 | top1-e-train: 0.013, top5-e-train: 0.005 | top1-e-test: 0.386, top5-e-test: 0.142\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.054 | top1-e-train: 0.018, top5-e-train: 0.010 | top1-e-test: 0.393, top5-e-test: 0.149\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.051 | top1-e-train: 0.012, top5-e-train: 0.005 | top1-e-test: 0.388, top5-e-test: 0.144\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.050 | top1-e-train: 0.011, top5-e-train: 0.004 | top1-e-test: 0.388, top5-e-test: 0.142\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.049 | top1-e-train: 0.014, top5-e-train: 0.007 | top1-e-test: 0.391, top5-e-test: 0.146\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.048 | top1-e-train: 0.013, top5-e-train: 0.005 | top1-e-test: 0.390, top5-e-test: 0.145\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.047 | top1-e-train: 0.011, top5-e-train: 0.004 | top1-e-test: 0.391, top5-e-test: 0.144\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.047 | top1-e-train: 0.010, top5-e-train: 0.005 | top1-e-test: 0.391, top5-e-test: 0.144\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.044 | top1-e-train: 0.010, top5-e-train: 0.004 | top1-e-test: 0.387, top5-e-test: 0.142\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.047 | top1-e-train: 0.012, top5-e-train: 0.005 | top1-e-test: 0.393, top5-e-test: 0.145\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.042 | top1-e-train: 0.011, top5-e-train: 0.005 | top1-e-test: 0.387, top5-e-test: 0.144\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.045 | top1-e-train: 0.014, top5-e-train: 0.008 | top1-e-test: 0.395, top5-e-test: 0.147\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.042 | top1-e-train: 0.010, top5-e-train: 0.004 | top1-e-test: 0.390, top5-e-test: 0.145\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.042 | top1-e-train: 0.010, top5-e-train: 0.005 | top1-e-test: 0.390, top5-e-test: 0.144\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.041 | top1-e-train: 0.008, top5-e-train: 0.003 | top1-e-test: 0.389, top5-e-test: 0.143\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.041 | top1-e-train: 0.011, top5-e-train: 0.005 | top1-e-test: 0.391, top5-e-test: 0.145\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.042 | top1-e-train: 0.010, top5-e-train: 0.004 | top1-e-test: 0.390, top5-e-test: 0.146\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.041 | top1-e-train: 0.007, top5-e-train: 0.002 | top1-e-test: 0.384, top5-e-test: 0.139\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.038 | top1-e-train: 0.009, top5-e-train: 0.004 | top1-e-test: 0.389, top5-e-test: 0.143\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.040 | top1-e-train: 0.011, top5-e-train: 0.006 | top1-e-test: 0.392, top5-e-test: 0.145\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.040 | top1-e-train: 0.010, top5-e-train: 0.005 | top1-e-test: 0.390, top5-e-test: 0.146\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.039 | top1-e-train: 0.014, top5-e-train: 0.008 | top1-e-test: 0.392, top5-e-test: 0.148\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.038 | top1-e-train: 0.009, top5-e-train: 0.005 | top1-e-test: 0.392, top5-e-test: 0.145\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.038 | top1-e-train: 0.009, top5-e-train: 0.004 | top1-e-test: 0.391, top5-e-test: 0.144\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.038 | top1-e-train: 0.012, top5-e-train: 0.007 | top1-e-test: 0.394, top5-e-test: 0.147\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.037 | top1-e-train: 0.010, top5-e-train: 0.005 | top1-e-test: 0.392, top5-e-test: 0.146\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.038 | top1-e-train: 0.009, top5-e-train: 0.005 | top1-e-test: 0.391, top5-e-test: 0.146\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.037 | top1-e-train: 0.009, top5-e-train: 0.004 | top1-e-test: 0.388, top5-e-test: 0.145\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.038 | top1-e-train: 0.007, top5-e-train: 0.003 | top1-e-test: 0.388, top5-e-test: 0.142\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.037 | top1-e-train: 0.010, top5-e-train: 0.005 | top1-e-test: 0.393, top5-e-test: 0.147\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.037 | top1-e-train: 0.010, top5-e-train: 0.005 | top1-e-test: 0.390, top5-e-test: 0.145\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.038 | top1-e-train: 0.009, top5-e-train: 0.004 | top1-e-test: 0.390, top5-e-test: 0.144\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.037 | top1-e-train: 0.009, top5-e-train: 0.004 | top1-e-test: 0.389, top5-e-test: 0.145\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.036 | top1-e-train: 0.009, top5-e-train: 0.005 | top1-e-test: 0.390, top5-e-test: 0.146\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.036 | top1-e-train: 0.009, top5-e-train: 0.004 | top1-e-test: 0.389, top5-e-test: 0.146\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.037 | top1-e-train: 0.010, top5-e-train: 0.005 | top1-e-test: 0.391, top5-e-test: 0.146\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.036 | top1-e-train: 0.012, top5-e-train: 0.007 | top1-e-test: 0.392, top5-e-test: 0.149\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.035 | top1-e-train: 0.008, top5-e-train: 0.003 | top1-e-test: 0.387, top5-e-test: 0.142\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.035 | top1-e-train: 0.009, top5-e-train: 0.005 | top1-e-test: 0.389, top5-e-test: 0.145\n",
            "--------- Finish Training --------\n",
            "Top1E:  0.381099998951\n",
            "Top5E:  0.138200044632\n",
            "\n",
            "\n",
            "e1_train:  [0.9648399949073792, 0.9295799732208252, 0.8795199990272522, 0.8236799836158752, 0.76146000623703, 0.7202399969100952, 0.6786999702453613, 0.641319990158081, 0.5989999771118164, 0.5677000284194946, 0.5431400537490845, 0.5279799699783325, 0.48510003089904785, 0.4787200093269348, 0.45124000310897827, 0.4252600073814392, 0.41492003202438354, 0.4033200144767761, 0.3758000135421753, 0.36726003885269165, 0.33970004320144653, 0.32179999351501465, 0.311240017414093, 0.29923999309539795, 0.27052003145217896, 0.2542800307273865, 0.24713999032974243, 0.234980046749115, 0.20987999439239502, 0.11968004703521729, 0.10076004266738892, 0.08942002058029175, 0.08483999967575073, 0.07712000608444214, 0.06994003057479858, 0.06530004739761353, 0.057840049266815186, 0.05474001169204712, 0.05070000886917114, 0.04394000768661499, 0.04360002279281616, 0.04268002510070801, 0.03868001699447632, 0.038420021533966064, 0.0323600172996521, 0.03058004379272461, 0.031320035457611084, 0.02836000919342041, 0.024960041046142578, 0.02378004789352417, 0.024500012397766113, 0.02258002758026123, 0.022480010986328125, 0.021960020065307617, 0.021120011806488037, 0.020160019397735596, 0.018060028553009033, 0.015400052070617676, 0.017859995365142822, 0.013060033321380615, 0.014740049839019775, 0.015139997005462646, 0.012820005416870117, 0.01756000518798828, 0.011640012264251709, 0.011140048503875732, 0.01428002119064331, 0.012900054454803467, 0.010720014572143555, 0.010480046272277832, 0.010399997234344482, 0.011979997158050537, 0.01100003719329834, 0.013999998569488525, 0.00998002290725708, 0.010100007057189941, 0.007880032062530518, 0.010780036449432373, 0.010220050811767578, 0.007120013236999512, 0.00866001844406128, 0.011320054531097412, 0.010120034217834473, 0.013640046119689941, 0.00932002067565918, 0.009080052375793457, 0.011900007724761963, 0.009900033473968506, 0.009460031986236572, 0.008980035781860352, 0.006660044193267822, 0.01016002893447876, 0.00998002290725708, 0.009039998054504395, 0.00896000862121582, 0.0091400146484375, 0.008980035781860352, 0.010179996490478516, 0.012440025806427002, 0.007880032062530518, 0.009479999542236328]\n",
            "e5_train:  [0.8567600250244141, 0.7477400302886963, 0.6406199932098389, 0.5364000201225281, 0.45552003383636475, 0.4036000370979309, 0.36142003536224365, 0.31550002098083496, 0.2726200222969055, 0.24532002210617065, 0.22206002473831177, 0.21286004781723022, 0.17757999897003174, 0.1800200343132019, 0.1535400152206421, 0.13836002349853516, 0.1273200511932373, 0.1188400387763977, 0.10651999711990356, 0.09888005256652832, 0.08562004566192627, 0.07710003852844238, 0.07124000787734985, 0.06460005044937134, 0.05378001928329468, 0.04912000894546509, 0.04177999496459961, 0.04100000858306885, 0.03270000219345093, 0.016840040683746338, 0.012480020523071289, 0.00952005386352539, 0.011220037937164307, 0.008240044116973877, 0.008440017700195312, 0.009020030498504639, 0.0064400434494018555, 0.0061800479888916016, 0.007080018520355225, 0.004680037498474121, 0.006300032138824463, 0.005820035934448242, 0.006120026111602783, 0.007320046424865723, 0.0039400458335876465, 0.003320038318634033, 0.005980014801025391, 0.005219995975494385, 0.004440009593963623, 0.004079997539520264, 0.004620015621185303, 0.004860043525695801, 0.004460036754608154, 0.005300045013427734, 0.00532001256942749, 0.005920052528381348, 0.0042000412940979, 0.0034600496292114258, 0.006099998950958252, 0.0035200119018554688, 0.005980014801025391, 0.0070400238037109375, 0.004720032215118408, 0.01016002893447876, 0.004640042781829834, 0.00448000431060791, 0.006720006465911865, 0.005180001258850098, 0.004060029983520508, 0.004760026931762695, 0.004160046577453613, 0.005360007286071777, 0.0048400163650512695, 0.007520020008087158, 0.0042999982833862305, 0.004680037498474121, 0.0029399991035461426, 0.005260050296783447, 0.004360020160675049, 0.0022600293159484863, 0.003560006618499756, 0.006280004978179932, 0.005120038986206055, 0.00802004337310791, 0.004700005054473877, 0.0037800073623657227, 0.006860017776489258, 0.005180001258850098, 0.0047800540924072266, 0.004280030727386475, 0.0026200413703918457, 0.005360007286071777, 0.0050400495529174805, 0.004400014877319336, 0.004400014877319336, 0.00466001033782959, 0.004140019416809082, 0.005280017852783203, 0.007480025291442871, 0.003040015697479248, 0.004960000514984131]\n",
            "\n",
            "\n",
            "e1_test:  [0.9660999774932861, 0.9266999959945679, 0.8773000240325928, 0.8148000240325928, 0.7577999830245972, 0.7182999849319458, 0.6789000034332275, 0.6454000473022461, 0.6061000227928162, 0.5848000049591064, 0.5644000172615051, 0.5587000250816345, 0.5253000259399414, 0.5224000215530396, 0.5078999996185303, 0.4936000108718872, 0.4983000159263611, 0.486299991607666, 0.47600001096725464, 0.4652000069618225, 0.454800009727478, 0.45910000801086426, 0.4553000330924988, 0.4546000361442566, 0.4343000054359436, 0.4399999976158142, 0.44440001249313354, 0.44200003147125244, 0.42339998483657837, 0.39010000228881836, 0.3863000273704529, 0.38109999895095825, 0.382099986076355, 0.38690000772476196, 0.3895000219345093, 0.38830000162124634, 0.39079999923706055, 0.3856000304222107, 0.3881000280380249, 0.3874000310897827, 0.3910999894142151, 0.39079999923706055, 0.3912000060081482, 0.3961000442504883, 0.3907000422477722, 0.390500009059906, 0.3889000415802002, 0.3935999870300293, 0.388200044631958, 0.3928000330924988, 0.3930000066757202, 0.3938000202178955, 0.3945000171661377, 0.3932000398635864, 0.3928999900817871, 0.3985000252723694, 0.3928000330924988, 0.39399999380111694, 0.3931000232696533, 0.38700002431869507, 0.3898000121116638, 0.39010000228881836, 0.3856000304222107, 0.3928999900817871, 0.38760000467300415, 0.38760000467300415, 0.390500009059906, 0.3898000121116638, 0.3906000256538391, 0.3913000226020813, 0.3871000409126282, 0.39259999990463257, 0.3873000144958496, 0.3945000171661377, 0.39010000228881836, 0.3895000219345093, 0.38850003480911255, 0.3910999894142151, 0.38999998569488525, 0.3842000365257263, 0.38850003480911255, 0.3920000195503235, 0.39020001888275146, 0.39240002632141113, 0.3921999931335449, 0.3906000256538391, 0.39350003004074097, 0.39160001277923584, 0.39090001583099365, 0.38830000162124634, 0.38780003786087036, 0.3927000164985657, 0.39030003547668457, 0.3896000385284424, 0.3888000249862671, 0.3903999924659729, 0.38910001516342163, 0.3910999894142151, 0.39170002937316895, 0.3871999979019165, 0.3889000415802002]\n",
            "e5_test:  [0.8514000177383423, 0.7409000396728516, 0.633400022983551, 0.5281000137329102, 0.45249998569488525, 0.406000018119812, 0.37240004539489746, 0.3228999972343445, 0.2851000428199768, 0.2705000042915344, 0.25130003690719604, 0.24639999866485596, 0.22400003671646118, 0.22870004177093506, 0.2079000473022461, 0.2013000249862671, 0.19630002975463867, 0.19350004196166992, 0.18639999628067017, 0.18040001392364502, 0.1779000163078308, 0.17450004816055298, 0.17640000581741333, 0.17330002784729004, 0.169700026512146, 0.16339999437332153, 0.163100004196167, 0.16940003633499146, 0.15400004386901855, 0.14600002765655518, 0.14219999313354492, 0.138200044631958, 0.1414000391960144, 0.14090001583099365, 0.1445000171661377, 0.14250004291534424, 0.1403999924659729, 0.14280003309249878, 0.140500009059906, 0.1413000226020813, 0.13960003852844238, 0.1406000256538391, 0.14300000667572021, 0.14730000495910645, 0.14350003004074097, 0.14270001649856567, 0.145300030708313, 0.14560002088546753, 0.14240002632141113, 0.1437000036239624, 0.14280003309249878, 0.1438000202178955, 0.14480000734329224, 0.14329999685287476, 0.14579999446868896, 0.14820003509521484, 0.14640003442764282, 0.14509999752044678, 0.14520001411437988, 0.140500009059906, 0.14340001344680786, 0.14430004358291626, 0.14240002632141113, 0.14880001544952393, 0.14399999380111694, 0.1421000361442566, 0.14579999446868896, 0.14480000734329224, 0.1439000368118286, 0.1437000036239624, 0.1420000195503235, 0.1454000473022461, 0.1437000036239624, 0.147100031375885, 0.1445000171661377, 0.1439000368118286, 0.14300000667572021, 0.1445000171661377, 0.14630001783370972, 0.13940000534057617, 0.14250004291534424, 0.1454000473022461, 0.14640003442764282, 0.147599995136261, 0.145300030708313, 0.1437000036239624, 0.14650005102157593, 0.14630001783370972, 0.14560002088546753, 0.145300030708313, 0.14180004596710205, 0.14680004119873047, 0.145300030708313, 0.14350003004074097, 0.14520001411437988, 0.14610004425048828, 0.14600002765655518, 0.14560002088546753, 0.14850002527236938, 0.1421000361442566, 0.14490002393722534]\n",
            "\n",
            "\n",
            "TIME:  9826.87873101\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n",
            "Namespace(arch='se_resnet50', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 4.383 | top1-e-train: 0.900, top5-e-train: 0.684 | top1-e-test: 0.899, top5-e-test: 0.675\n",
            "[Epoch   1], lr: 0.10000, Loss: 3.585 | top1-e-train: 0.804, top5-e-train: 0.509 | top1-e-test: 0.790, top5-e-test: 0.500\n",
            "[Epoch   2], lr: 0.10000, Loss: 3.099 | top1-e-train: 0.735, top5-e-train: 0.416 | top1-e-test: 0.734, top5-e-test: 0.419\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.732 | top1-e-train: 0.692, top5-e-train: 0.359 | top1-e-test: 0.684, top5-e-test: 0.347\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.455 | top1-e-train: 0.643, top5-e-train: 0.317 | top1-e-test: 0.649, top5-e-test: 0.324\n",
            "[Epoch   5], lr: 0.10000, Loss: 2.242 | top1-e-train: 0.581, top5-e-train: 0.254 | top1-e-test: 0.597, top5-e-test: 0.281\n",
            "[Epoch   6], lr: 0.10000, Loss: 2.058 | top1-e-train: 0.537, top5-e-train: 0.213 | top1-e-test: 0.561, top5-e-test: 0.241\n",
            "[Epoch   7], lr: 0.10000, Loss: 1.901 | top1-e-train: 0.513, top5-e-train: 0.197 | top1-e-test: 0.552, top5-e-test: 0.235\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.774 | top1-e-train: 0.478, top5-e-train: 0.167 | top1-e-test: 0.526, top5-e-test: 0.213\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.652 | top1-e-train: 0.438, top5-e-train: 0.146 | top1-e-test: 0.502, top5-e-test: 0.201\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.550 | top1-e-train: 0.413, top5-e-train: 0.128 | top1-e-test: 0.491, top5-e-test: 0.188\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.446 | top1-e-train: 0.384, top5-e-train: 0.115 | top1-e-test: 0.477, top5-e-test: 0.184\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.354 | top1-e-train: 0.372, top5-e-train: 0.095 | top1-e-test: 0.478, top5-e-test: 0.180\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.262 | top1-e-train: 0.352, top5-e-train: 0.091 | top1-e-test: 0.466, top5-e-test: 0.179\n",
            "[Epoch  14], lr: 0.10000, Loss: 1.188 | top1-e-train: 0.326, top5-e-train: 0.074 | top1-e-test: 0.458, top5-e-test: 0.167\n",
            "[Epoch  15], lr: 0.10000, Loss: 1.092 | top1-e-train: 0.292, top5-e-train: 0.063 | top1-e-test: 0.440, top5-e-test: 0.165\n",
            "[Epoch  16], lr: 0.10000, Loss: 1.023 | top1-e-train: 0.276, top5-e-train: 0.055 | top1-e-test: 0.437, top5-e-test: 0.162\n",
            "[Epoch  17], lr: 0.10000, Loss: 0.941 | top1-e-train: 0.297, top5-e-train: 0.073 | top1-e-test: 0.470, top5-e-test: 0.189\n",
            "[Epoch  18], lr: 0.10000, Loss: 0.874 | top1-e-train: 0.229, top5-e-train: 0.039 | top1-e-test: 0.442, top5-e-test: 0.158\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.799 | top1-e-train: 0.205, top5-e-train: 0.030 | top1-e-test: 0.428, top5-e-test: 0.154\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.750 | top1-e-train: 0.207, top5-e-train: 0.028 | top1-e-test: 0.435, top5-e-test: 0.156\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.696 | top1-e-train: 0.186, top5-e-train: 0.022 | top1-e-test: 0.429, top5-e-test: 0.153\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.623 | top1-e-train: 0.160, top5-e-train: 0.016 | top1-e-test: 0.413, top5-e-test: 0.151\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.564 | top1-e-train: 0.150, top5-e-train: 0.013 | top1-e-test: 0.427, top5-e-test: 0.156\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.506 | top1-e-train: 0.137, top5-e-train: 0.011 | top1-e-test: 0.421, top5-e-test: 0.156\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.457 | top1-e-train: 0.123, top5-e-train: 0.011 | top1-e-test: 0.420, top5-e-test: 0.154\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.410 | top1-e-train: 0.125, top5-e-train: 0.009 | top1-e-test: 0.425, top5-e-test: 0.155\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.368 | top1-e-train: 0.100, top5-e-train: 0.005 | top1-e-test: 0.418, top5-e-test: 0.155\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.330 | top1-e-train: 0.090, top5-e-train: 0.008 | top1-e-test: 0.414, top5-e-test: 0.155\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.159 | top1-e-train: 0.028, top5-e-train: 0.001 | top1-e-test: 0.380, top5-e-test: 0.132\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.103 | top1-e-train: 0.019, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.128\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.084 | top1-e-train: 0.016, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.128\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.074 | top1-e-train: 0.014, top5-e-train: 0.001 | top1-e-test: 0.371, top5-e-test: 0.129\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.064 | top1-e-train: 0.013, top5-e-train: 0.001 | top1-e-test: 0.370, top5-e-test: 0.129\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.058 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.370, top5-e-test: 0.126\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.053 | top1-e-train: 0.011, top5-e-train: 0.001 | top1-e-test: 0.369, top5-e-test: 0.126\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.050 | top1-e-train: 0.010, top5-e-train: 0.001 | top1-e-test: 0.368, top5-e-test: 0.127\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.044 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.125\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.041 | top1-e-train: 0.009, top5-e-train: 0.000 | top1-e-test: 0.369, top5-e-test: 0.126\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.040 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.126\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.036 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.367, top5-e-test: 0.125\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.035 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.367, top5-e-test: 0.125\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.030 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.125\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.030 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.367, top5-e-test: 0.126\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.031 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.127\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.028 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.127\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.027 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.125\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.026 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.368, top5-e-test: 0.126\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.126\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.126\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.021 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.021 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.126\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.019 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.127\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.019 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.127\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.019 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.127\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.019 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.017 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.126\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.126\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.361, top5-e-test: 0.126\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.125\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.127\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.361, top5-e-test: 0.127\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.127\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.126\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.126\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.126\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.125\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.127\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.126\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.128\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.126\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.128\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.126\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.127\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.125\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.126\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.127\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.361, top5-e-test: 0.127\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.126\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.125\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.128\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.127\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.127\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.125\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.127\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.127\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.011 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.126\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.361, top5-e-test: 0.128\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.127\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.127\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.368, top5-e-test: 0.126\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.011 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.126\n",
            "--------- Finish Training --------\n",
            "Top1E:  0.361100018024\n",
            "Top5E:  0.124800026417\n",
            "\n",
            "\n",
            "e1_train:  [0.8997399806976318, 0.8043000102043152, 0.735480010509491, 0.6916600465774536, 0.6428599953651428, 0.5812599658966064, 0.5366799831390381, 0.513200044631958, 0.47788000106811523, 0.43818002939224243, 0.41280001401901245, 0.38447999954223633, 0.37191998958587646, 0.3520200252532959, 0.32618004083633423, 0.29214000701904297, 0.2755200266838074, 0.29736000299453735, 0.2286199927330017, 0.20548003911972046, 0.20692002773284912, 0.18610000610351562, 0.1601000428199768, 0.1499200463294983, 0.13712000846862793, 0.12282001972198486, 0.12547999620437622, 0.09970003366470337, 0.09040004014968872, 0.027840018272399902, 0.018900036811828613, 0.016180038452148438, 0.014340043067932129, 0.013040006160736084, 0.010680019855499268, 0.01061999797821045, 0.009640038013458252, 0.007100045680999756, 0.008599996566772461, 0.006300032138824463, 0.006640017032623291, 0.005080044269561768, 0.0040400028228759766, 0.004519999027252197, 0.004760026931762695, 0.004260003566741943, 0.004860043525695801, 0.0042400360107421875, 0.004100024700164795, 0.0042400360107421875, 0.002780020236968994, 0.0025600194931030273, 0.0033600330352783203, 0.003340005874633789, 0.003000020980834961, 0.0034600496292114258, 0.0026000142097473145, 0.002140045166015625, 0.0025200247764587402, 0.0028400421142578125, 0.0020599961280822754, 0.0026200413703918457, 0.0026200413703918457, 0.002460002899169922, 0.002180039882659912, 0.004180014133453369, 0.002140045166015625, 0.0020200014114379883, 0.002279996871948242, 0.0017600059509277344, 0.0020599961280822754, 0.0016600489616394043, 0.0019600391387939453, 0.0020599961280822754, 0.002660036087036133, 0.0031800270080566406, 0.0020400285720825195, 0.0016800165176391602, 0.002480030059814453, 0.0016200542449951172, 0.0014600157737731934, 0.0015799999237060547, 0.0015799999237060547, 0.001900017261505127, 0.0019200444221496582, 0.0013599991798400879, 0.0020400285720825195, 0.0019600391387939453, 0.0012000203132629395, 0.0017800331115722656, 0.0013800263404846191, 0.001940011978149414, 0.003200054168701172, 0.002200007438659668, 0.0019600391387939453, 0.0013599991798400879, 0.0018200278282165527, 0.002100050449371338, 0.0014200210571289062, 0.0025800466537475586, 0.0026800036430358887]\n",
            "e5_train:  [0.6837999820709229, 0.5085999965667725, 0.41610002517700195, 0.35944002866744995, 0.31682002544403076, 0.2541000247001648, 0.2127400040626526, 0.19666004180908203, 0.16694003343582153, 0.14608001708984375, 0.12758004665374756, 0.11504000425338745, 0.09494000673294067, 0.09138000011444092, 0.07406002283096313, 0.06270003318786621, 0.055299997329711914, 0.07332003116607666, 0.038920044898986816, 0.029840052127838135, 0.027500033378601074, 0.02176004648208618, 0.01624000072479248, 0.01332002878189087, 0.011200010776519775, 0.010500013828277588, 0.009380042552947998, 0.005260050296783447, 0.008440017700195312, 0.0013599991798400879, 0.0004000067710876465, 0.0004799962043762207, 0.0006400346755981445, 0.001000046730041504, 0.0003800392150878906, 0.0006800293922424316, 0.0006400346755981445, 4.00543212890625e-05, 0.00042003393173217773, 0.00012004375457763672, 0.00012004375457763672, 0.00010001659393310547, 2.002716064453125e-05, 4.00543212890625e-05, 2.002716064453125e-05, 2.002716064453125e-05, 0.00010001659393310547, 0.00012004375457763672, 0.00010001659393310547, 2.002716064453125e-05, 2.002716064453125e-05, 0.0, 6.002187728881836e-05, 6.002187728881836e-05, 8.004903793334961e-05, 0.00016003847122192383, 0.0, 0.0, 4.00543212890625e-05, 0.00012004375457763672, 0.0, 0.00016003847122192383, 0.00012004375457763672, 4.00543212890625e-05, 2.002716064453125e-05, 0.0002200007438659668, 6.002187728881836e-05, 2.002716064453125e-05, 6.002187728881836e-05, 0.0, 2.002716064453125e-05, 2.002716064453125e-05, 6.002187728881836e-05, 8.004903793334961e-05, 0.00016003847122192383, 0.0002599954605102539, 8.004903793334961e-05, 0.0, 0.00012004375457763672, 2.002716064453125e-05, 2.002716064453125e-05, 0.0, 0.0, 8.004903793334961e-05, 4.00543212890625e-05, 2.002716064453125e-05, 0.00010001659393310547, 0.00012004375457763672, 0.0, 4.00543212890625e-05, 0.0, 8.004903793334961e-05, 0.00024002790451049805, 4.00543212890625e-05, 6.002187728881836e-05, 0.0, 6.002187728881836e-05, 0.00010001659393310547, 2.002716064453125e-05, 0.00016003847122192383, 0.00012004375457763672]\n",
            "\n",
            "\n",
            "e1_test:  [0.8992000222206116, 0.7900000214576721, 0.7335000038146973, 0.6837999820709229, 0.6491000056266785, 0.5965999960899353, 0.5605000257492065, 0.5519000291824341, 0.5256999731063843, 0.501800000667572, 0.49070000648498535, 0.4771000146865845, 0.47780001163482666, 0.46560001373291016, 0.4577000141143799, 0.4401000142097473, 0.4368000030517578, 0.4702000021934509, 0.4415000081062317, 0.42760002613067627, 0.4345000386238098, 0.42910003662109375, 0.4129999876022339, 0.4272000193595886, 0.4212000370025635, 0.42000001668930054, 0.42489999532699585, 0.4183000326156616, 0.4139000177383423, 0.37959998846054077, 0.3733000159263611, 0.3709999918937683, 0.3712000250816345, 0.3702999949455261, 0.36959999799728394, 0.36900001764297485, 0.3677999973297119, 0.364300012588501, 0.3691999912261963, 0.3659999966621399, 0.3670000433921814, 0.3666999936103821, 0.36410003900527954, 0.36660003662109375, 0.36480003595352173, 0.36590003967285156, 0.3654000163078308, 0.3676000237464905, 0.36510002613067627, 0.3634999990463257, 0.3637000322341919, 0.36320000886917114, 0.3637000322341919, 0.36419999599456787, 0.36489999294281006, 0.36580002307891846, 0.36260002851486206, 0.3634999990463257, 0.3637000322341919, 0.3628000020980835, 0.3614000082015991, 0.36480003595352173, 0.3647000193595886, 0.36320000886917114, 0.3611000180244446, 0.36559998989105225, 0.3634999990463257, 0.36239999532699585, 0.3644000291824341, 0.36250001192092896, 0.3634999990463257, 0.3615000247955322, 0.3621000051498413, 0.3637000322341919, 0.36410003900527954, 0.36489999294281006, 0.3636000156402588, 0.36489999294281006, 0.364300012588501, 0.3629000186920166, 0.3621000051498413, 0.3623000383377075, 0.361299991607666, 0.36309999227523804, 0.3628000020980835, 0.36169999837875366, 0.36419999599456787, 0.3644000291824341, 0.36320000886917114, 0.3637000322341919, 0.3619999885559082, 0.3644000291824341, 0.3636000156402588, 0.3646000027656555, 0.3634999990463257, 0.3614000082015991, 0.3630000352859497, 0.3652999997138977, 0.3629000186920166, 0.3676000237464905, 0.36480003595352173]\n",
            "e5_test:  [0.6748999953269958, 0.49980002641677856, 0.4194999933242798, 0.3474000096321106, 0.323900043964386, 0.28060001134872437, 0.24050003290176392, 0.23489999771118164, 0.21250003576278687, 0.2005000114440918, 0.1876000165939331, 0.18380004167556763, 0.18000000715255737, 0.1788000464439392, 0.16680002212524414, 0.16460001468658447, 0.16170001029968262, 0.18870002031326294, 0.15770000219345093, 0.1535000205039978, 0.15610003471374512, 0.15310001373291016, 0.15130001306533813, 0.15580004453659058, 0.1559000015258789, 0.15390002727508545, 0.15530002117156982, 0.15549999475479126, 0.15470004081726074, 0.131600022315979, 0.1281999945640564, 0.12810003757476807, 0.12890005111694336, 0.12929999828338623, 0.1260000467300415, 0.12620002031326294, 0.12650001049041748, 0.1252000331878662, 0.1258000135421753, 0.1260000467300415, 0.1251000165939331, 0.1251000165939331, 0.12540000677108765, 0.1258000135421753, 0.12710005044937134, 0.1267000436782837, 0.12480002641677856, 0.12620002031326294, 0.12620002031326294, 0.12650001049041748, 0.12550002336502075, 0.1267000436782837, 0.1260000467300415, 0.12710005044937134, 0.12660002708435059, 0.12720000743865967, 0.12660002708435059, 0.12690001726150513, 0.12630003690719604, 0.1260000467300415, 0.12610000371932983, 0.12530004978179932, 0.12710005044937134, 0.12720000743865967, 0.12650001049041748, 0.1274999976158142, 0.12720000743865967, 0.1259000301361084, 0.1259000301361084, 0.12740004062652588, 0.1260000467300415, 0.12540000677108765, 0.1274999976158142, 0.12630003690719604, 0.1283000111579895, 0.12620002031326294, 0.12790000438690186, 0.1260000467300415, 0.12700003385543823, 0.1252000331878662, 0.1260000467300415, 0.12730002403259277, 0.12710005044937134, 0.12690001726150513, 0.12630003690719604, 0.12540000677108765, 0.12790000438690186, 0.12700003385543823, 0.1274999976158142, 0.12690001726150513, 0.12490004301071167, 0.12720000743865967, 0.12660002708435059, 0.12620002031326294, 0.12660002708435059, 0.12770003080368042, 0.12650001049041748, 0.12700003385543823, 0.12690001726150513, 0.12620002031326294, 0.12620002031326294]\n",
            "\n",
            "\n",
            "TIME:  11110.907479\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n",
            "Namespace(arch='bam_resnet50', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 4.906 | top1-e-train: 0.975, top5-e-train: 0.885 | top1-e-test: 0.974, top5-e-test: 0.885\n",
            "[Epoch   1], lr: 0.10000, Loss: 4.293 | top1-e-train: 0.946, top5-e-train: 0.806 | top1-e-test: 0.940, top5-e-test: 0.796\n",
            "[Epoch   2], lr: 0.10000, Loss: 4.026 | top1-e-train: 0.910, top5-e-train: 0.695 | top1-e-test: 0.906, top5-e-test: 0.690\n",
            "[Epoch   3], lr: 0.10000, Loss: 3.768 | top1-e-train: 0.871, top5-e-train: 0.625 | top1-e-test: 0.859, top5-e-test: 0.610\n",
            "[Epoch   4], lr: 0.10000, Loss: 3.533 | top1-e-train: 0.821, top5-e-train: 0.550 | top1-e-test: 0.815, top5-e-test: 0.542\n",
            "[Epoch   5], lr: 0.10000, Loss: 3.328 | top1-e-train: 0.792, top5-e-train: 0.497 | top1-e-test: 0.779, top5-e-test: 0.490\n",
            "[Epoch   6], lr: 0.10000, Loss: 3.145 | top1-e-train: 0.758, top5-e-train: 0.455 | top1-e-test: 0.747, top5-e-test: 0.453\n",
            "[Epoch   7], lr: 0.10000, Loss: 2.986 | top1-e-train: 0.721, top5-e-train: 0.405 | top1-e-test: 0.717, top5-e-test: 0.404\n",
            "[Epoch   8], lr: 0.10000, Loss: 2.825 | top1-e-train: 0.706, top5-e-train: 0.386 | top1-e-test: 0.706, top5-e-test: 0.387\n",
            "[Epoch   9], lr: 0.10000, Loss: 2.671 | top1-e-train: 0.669, top5-e-train: 0.346 | top1-e-test: 0.667, top5-e-test: 0.354\n",
            "[Epoch  10], lr: 0.10000, Loss: 2.532 | top1-e-train: 0.622, top5-e-train: 0.299 | top1-e-test: 0.628, top5-e-test: 0.310\n",
            "[Epoch  11], lr: 0.10000, Loss: 2.411 | top1-e-train: 0.594, top5-e-train: 0.274 | top1-e-test: 0.613, top5-e-test: 0.298\n",
            "[Epoch  12], lr: 0.10000, Loss: 2.293 | top1-e-train: 0.585, top5-e-train: 0.263 | top1-e-test: 0.607, top5-e-test: 0.290\n",
            "[Epoch  13], lr: 0.10000, Loss: 2.199 | top1-e-train: 0.566, top5-e-train: 0.248 | top1-e-test: 0.586, top5-e-test: 0.270\n",
            "[Epoch  14], lr: 0.10000, Loss: 2.098 | top1-e-train: 0.536, top5-e-train: 0.222 | top1-e-test: 0.566, top5-e-test: 0.256\n",
            "[Epoch  15], lr: 0.10000, Loss: 2.009 | top1-e-train: 0.524, top5-e-train: 0.208 | top1-e-test: 0.563, top5-e-test: 0.249\n",
            "[Epoch  16], lr: 0.10000, Loss: 1.927 | top1-e-train: 0.490, top5-e-train: 0.188 | top1-e-test: 0.534, top5-e-test: 0.241\n",
            "[Epoch  17], lr: 0.10000, Loss: 1.848 | top1-e-train: 0.469, top5-e-train: 0.174 | top1-e-test: 0.524, top5-e-test: 0.226\n",
            "[Epoch  18], lr: 0.10000, Loss: 1.769 | top1-e-train: 0.467, top5-e-train: 0.165 | top1-e-test: 0.525, top5-e-test: 0.231\n",
            "[Epoch  19], lr: 0.10000, Loss: 1.705 | top1-e-train: 0.447, top5-e-train: 0.153 | top1-e-test: 0.520, top5-e-test: 0.222\n",
            "[Epoch  20], lr: 0.10000, Loss: 1.636 | top1-e-train: 0.420, top5-e-train: 0.137 | top1-e-test: 0.508, top5-e-test: 0.217\n",
            "[Epoch  21], lr: 0.10000, Loss: 1.559 | top1-e-train: 0.417, top5-e-train: 0.137 | top1-e-test: 0.499, top5-e-test: 0.215\n",
            "[Epoch  22], lr: 0.10000, Loss: 1.500 | top1-e-train: 0.390, top5-e-train: 0.118 | top1-e-test: 0.495, top5-e-test: 0.209\n",
            "[Epoch  23], lr: 0.10000, Loss: 1.429 | top1-e-train: 0.386, top5-e-train: 0.114 | top1-e-test: 0.494, top5-e-test: 0.209\n",
            "[Epoch  24], lr: 0.10000, Loss: 1.370 | top1-e-train: 0.358, top5-e-train: 0.101 | top1-e-test: 0.494, top5-e-test: 0.207\n",
            "[Epoch  25], lr: 0.10000, Loss: 1.314 | top1-e-train: 0.337, top5-e-train: 0.087 | top1-e-test: 0.474, top5-e-test: 0.194\n",
            "[Epoch  26], lr: 0.10000, Loss: 1.255 | top1-e-train: 0.330, top5-e-train: 0.089 | top1-e-test: 0.481, top5-e-test: 0.207\n",
            "[Epoch  27], lr: 0.10000, Loss: 1.196 | top1-e-train: 0.314, top5-e-train: 0.077 | top1-e-test: 0.484, top5-e-test: 0.203\n",
            "[Epoch  28], lr: 0.10000, Loss: 1.134 | top1-e-train: 0.309, top5-e-train: 0.074 | top1-e-test: 0.484, top5-e-test: 0.201\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.810 | top1-e-train: 0.196, top5-e-train: 0.035 | top1-e-test: 0.435, top5-e-test: 0.165\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.695 | top1-e-train: 0.180, top5-e-train: 0.033 | top1-e-test: 0.435, top5-e-test: 0.168\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.645 | top1-e-train: 0.162, top5-e-train: 0.027 | top1-e-test: 0.433, top5-e-test: 0.169\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.604 | top1-e-train: 0.152, top5-e-train: 0.024 | top1-e-test: 0.431, top5-e-test: 0.166\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.565 | top1-e-train: 0.144, top5-e-train: 0.022 | top1-e-test: 0.434, top5-e-test: 0.168\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.533 | top1-e-train: 0.132, top5-e-train: 0.019 | top1-e-test: 0.432, top5-e-test: 0.169\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.504 | top1-e-train: 0.126, top5-e-train: 0.019 | top1-e-test: 0.435, top5-e-test: 0.170\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.474 | top1-e-train: 0.116, top5-e-train: 0.018 | top1-e-test: 0.436, top5-e-test: 0.172\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.444 | top1-e-train: 0.108, top5-e-train: 0.015 | top1-e-test: 0.436, top5-e-test: 0.169\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.424 | top1-e-train: 0.108, top5-e-train: 0.015 | top1-e-test: 0.438, top5-e-test: 0.175\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.401 | top1-e-train: 0.098, top5-e-train: 0.017 | top1-e-test: 0.443, top5-e-test: 0.178\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.376 | top1-e-train: 0.087, top5-e-train: 0.012 | top1-e-test: 0.438, top5-e-test: 0.175\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.359 | top1-e-train: 0.082, top5-e-train: 0.009 | top1-e-test: 0.437, top5-e-test: 0.175\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.341 | top1-e-train: 0.075, top5-e-train: 0.008 | top1-e-test: 0.436, top5-e-test: 0.174\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.313 | top1-e-train: 0.074, top5-e-train: 0.012 | top1-e-test: 0.439, top5-e-test: 0.179\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.295 | top1-e-train: 0.066, top5-e-train: 0.007 | top1-e-test: 0.436, top5-e-test: 0.177\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.281 | top1-e-train: 0.061, top5-e-train: 0.008 | top1-e-test: 0.442, top5-e-test: 0.180\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.264 | top1-e-train: 0.058, top5-e-train: 0.006 | top1-e-test: 0.438, top5-e-test: 0.178\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.251 | top1-e-train: 0.055, top5-e-train: 0.008 | top1-e-test: 0.438, top5-e-test: 0.182\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.236 | top1-e-train: 0.050, top5-e-train: 0.006 | top1-e-test: 0.433, top5-e-test: 0.180\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.227 | top1-e-train: 0.047, top5-e-train: 0.008 | top1-e-test: 0.444, top5-e-test: 0.182\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.215 | top1-e-train: 0.044, top5-e-train: 0.007 | top1-e-test: 0.443, top5-e-test: 0.184\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.201 | top1-e-train: 0.040, top5-e-train: 0.006 | top1-e-test: 0.436, top5-e-test: 0.180\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.190 | top1-e-train: 0.038, top5-e-train: 0.006 | top1-e-test: 0.439, top5-e-test: 0.183\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.181 | top1-e-train: 0.036, top5-e-train: 0.005 | top1-e-test: 0.440, top5-e-test: 0.179\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.169 | top1-e-train: 0.035, top5-e-train: 0.005 | top1-e-test: 0.437, top5-e-test: 0.185\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.163 | top1-e-train: 0.033, top5-e-train: 0.006 | top1-e-test: 0.438, top5-e-test: 0.183\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.159 | top1-e-train: 0.032, top5-e-train: 0.005 | top1-e-test: 0.442, top5-e-test: 0.181\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.149 | top1-e-train: 0.035, top5-e-train: 0.011 | top1-e-test: 0.441, top5-e-test: 0.188\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.143 | top1-e-train: 0.027, top5-e-train: 0.006 | top1-e-test: 0.439, top5-e-test: 0.181\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.116 | top1-e-train: 0.020, top5-e-train: 0.003 | top1-e-test: 0.433, top5-e-test: 0.177\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.103 | top1-e-train: 0.021, top5-e-train: 0.005 | top1-e-test: 0.435, top5-e-test: 0.179\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.097 | top1-e-train: 0.019, top5-e-train: 0.003 | top1-e-test: 0.435, top5-e-test: 0.177\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.097 | top1-e-train: 0.019, top5-e-train: 0.005 | top1-e-test: 0.435, top5-e-test: 0.180\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.094 | top1-e-train: 0.021, top5-e-train: 0.008 | top1-e-test: 0.438, top5-e-test: 0.183\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.090 | top1-e-train: 0.020, top5-e-train: 0.008 | top1-e-test: 0.438, top5-e-test: 0.181\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.089 | top1-e-train: 0.018, top5-e-train: 0.005 | top1-e-test: 0.432, top5-e-test: 0.180\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.085 | top1-e-train: 0.018, top5-e-train: 0.006 | top1-e-test: 0.435, top5-e-test: 0.179\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.084 | top1-e-train: 0.018, top5-e-train: 0.007 | top1-e-test: 0.434, top5-e-test: 0.180\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.081 | top1-e-train: 0.015, top5-e-train: 0.003 | top1-e-test: 0.431, top5-e-test: 0.175\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.082 | top1-e-train: 0.015, top5-e-train: 0.004 | top1-e-test: 0.435, top5-e-test: 0.177\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.081 | top1-e-train: 0.015, top5-e-train: 0.004 | top1-e-test: 0.434, top5-e-test: 0.178\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.080 | top1-e-train: 0.016, top5-e-train: 0.005 | top1-e-test: 0.436, top5-e-test: 0.178\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.079 | top1-e-train: 0.014, top5-e-train: 0.003 | top1-e-test: 0.435, top5-e-test: 0.174\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.078 | top1-e-train: 0.016, top5-e-train: 0.006 | top1-e-test: 0.436, top5-e-test: 0.181\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.077 | top1-e-train: 0.014, top5-e-train: 0.003 | top1-e-test: 0.433, top5-e-test: 0.178\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.072 | top1-e-train: 0.013, top5-e-train: 0.004 | top1-e-test: 0.435, top5-e-test: 0.178\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.076 | top1-e-train: 0.015, top5-e-train: 0.005 | top1-e-test: 0.433, top5-e-test: 0.182\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.075 | top1-e-train: 0.014, top5-e-train: 0.005 | top1-e-test: 0.432, top5-e-test: 0.178\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.073 | top1-e-train: 0.013, top5-e-train: 0.004 | top1-e-test: 0.431, top5-e-test: 0.178\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.072 | top1-e-train: 0.015, top5-e-train: 0.006 | top1-e-test: 0.433, top5-e-test: 0.182\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.069 | top1-e-train: 0.015, top5-e-train: 0.007 | top1-e-test: 0.434, top5-e-test: 0.181\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.070 | top1-e-train: 0.016, top5-e-train: 0.008 | top1-e-test: 0.435, top5-e-test: 0.184\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.068 | top1-e-train: 0.015, top5-e-train: 0.006 | top1-e-test: 0.433, top5-e-test: 0.181\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.066 | top1-e-train: 0.016, top5-e-train: 0.007 | top1-e-test: 0.435, top5-e-test: 0.183\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.069 | top1-e-train: 0.014, top5-e-train: 0.006 | top1-e-test: 0.433, top5-e-test: 0.182\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.068 | top1-e-train: 0.014, top5-e-train: 0.006 | top1-e-test: 0.435, top5-e-test: 0.181\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.066 | top1-e-train: 0.013, top5-e-train: 0.005 | top1-e-test: 0.434, top5-e-test: 0.180\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.065 | top1-e-train: 0.013, top5-e-train: 0.005 | top1-e-test: 0.432, top5-e-test: 0.182\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.065 | top1-e-train: 0.011, top5-e-train: 0.003 | top1-e-test: 0.433, top5-e-test: 0.178\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.065 | top1-e-train: 0.015, top5-e-train: 0.008 | top1-e-test: 0.436, top5-e-test: 0.183\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.063 | top1-e-train: 0.017, top5-e-train: 0.009 | top1-e-test: 0.437, top5-e-test: 0.185\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.063 | top1-e-train: 0.012, top5-e-train: 0.005 | top1-e-test: 0.434, top5-e-test: 0.180\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.063 | top1-e-train: 0.012, top5-e-train: 0.004 | top1-e-test: 0.433, top5-e-test: 0.177\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.063 | top1-e-train: 0.016, top5-e-train: 0.008 | top1-e-test: 0.436, top5-e-test: 0.185\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.062 | top1-e-train: 0.013, top5-e-train: 0.005 | top1-e-test: 0.433, top5-e-test: 0.181\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.062 | top1-e-train: 0.017, top5-e-train: 0.010 | top1-e-test: 0.437, top5-e-test: 0.186\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.063 | top1-e-train: 0.013, top5-e-train: 0.006 | top1-e-test: 0.435, top5-e-test: 0.181\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.062 | top1-e-train: 0.013, top5-e-train: 0.006 | top1-e-test: 0.434, top5-e-test: 0.182\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.060 | top1-e-train: 0.013, top5-e-train: 0.006 | top1-e-test: 0.434, top5-e-test: 0.180\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.061 | top1-e-train: 0.013, top5-e-train: 0.005 | top1-e-test: 0.434, top5-e-test: 0.182\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.061 | top1-e-train: 0.012, top5-e-train: 0.005 | top1-e-test: 0.432, top5-e-test: 0.181\n",
            "--------- Finish Training --------\n",
            "Top1E:  0.431100010872\n",
            "Top5E:  0.164900004864\n",
            "\n",
            "\n",
            "e1_train:  [0.975380003452301, 0.946399986743927, 0.9099600315093994, 0.8713799715042114, 0.8208400011062622, 0.7915400266647339, 0.7581200003623962, 0.7206799983978271, 0.7055599689483643, 0.6691200137138367, 0.6221400499343872, 0.5943000316619873, 0.5851800441741943, 0.5659600496292114, 0.5363399982452393, 0.5236200094223022, 0.48962002992630005, 0.4686200022697449, 0.4665600061416626, 0.4466000199317932, 0.4204000234603882, 0.41746002435684204, 0.38978004455566406, 0.38565999269485474, 0.35774004459381104, 0.3373200297355652, 0.33044004440307617, 0.3144400119781494, 0.30904000997543335, 0.1962200403213501, 0.18046003580093384, 0.16192001104354858, 0.15244001150131226, 0.14416003227233887, 0.1324000358581543, 0.125760018825531, 0.11577999591827393, 0.10792005062103271, 0.10790002346038818, 0.09842002391815186, 0.08726000785827637, 0.08204001188278198, 0.0746999979019165, 0.07402002811431885, 0.06568002700805664, 0.06069999933242798, 0.05823999643325806, 0.05512005090713501, 0.04956001043319702, 0.04686003923416138, 0.0444599986076355, 0.040220022201538086, 0.03816002607345581, 0.035920023918151855, 0.03502005338668823, 0.032739996910095215, 0.03214001655578613, 0.03452003002166748, 0.02688002586364746, 0.019700050354003906, 0.02101999521255493, 0.01876002550125122, 0.019020020961761475, 0.021480023860931396, 0.019800007343292236, 0.017700016498565674, 0.017520010471343994, 0.017859995365142822, 0.015340030193328857, 0.015280008316040039, 0.014940023422241211, 0.016279995441436768, 0.014380037784576416, 0.01566004753112793, 0.01410001516342163, 0.013480007648468018, 0.014980018138885498, 0.01380002498626709, 0.013020038604736328, 0.014980018138885498, 0.014960050582885742, 0.01578003168106079, 0.014740049839019775, 0.016180038452148438, 0.013640046119689941, 0.013680040836334229, 0.012800037860870361, 0.012900054454803467, 0.01061999797821045, 0.014560043811798096, 0.016660034656524658, 0.012199997901916504, 0.011720001697540283, 0.016060054302215576, 0.012540042400360107, 0.017000019550323486, 0.01278001070022583, 0.01278001070022583, 0.013200044631958008, 0.0126800537109375, 0.012360036373138428]\n",
            "e5_train:  [0.8853399753570557, 0.8058000206947327, 0.694640040397644, 0.6247400045394897, 0.5504800081253052, 0.49734002351760864, 0.45482003688812256, 0.4050999879837036, 0.38618004322052, 0.34592002630233765, 0.29868000745773315, 0.274120032787323, 0.2630600333213806, 0.24766004085540771, 0.22176003456115723, 0.20840001106262207, 0.18841999769210815, 0.17406004667282104, 0.16460001468658447, 0.15332001447677612, 0.13712000846862793, 0.1370600461959839, 0.11792004108428955, 0.1139799952507019, 0.10110002756118774, 0.08724004030227661, 0.08924001455307007, 0.07719999551773071, 0.0738600492477417, 0.03510004281997681, 0.03286004066467285, 0.026960015296936035, 0.0238800048828125, 0.02246004343032837, 0.01942002773284912, 0.01910001039505005, 0.01780003309249878, 0.01510000228881836, 0.015160024166107178, 0.016520023345947266, 0.01241999864578247, 0.00896000862121582, 0.008280038833618164, 0.01175999641418457, 0.006940007209777832, 0.007620036602020264, 0.006400048732757568, 0.007980048656463623, 0.006080031394958496, 0.008240044116973877, 0.007160007953643799, 0.006300032138824463, 0.006200015544891357, 0.0048400163650512695, 0.004620015621185303, 0.006260037422180176, 0.004900038242340088, 0.01061999797821045, 0.005560040473937988, 0.003260016441345215, 0.005200028419494629, 0.0028000473976135254, 0.004739999771118164, 0.008240044116973877, 0.0075400471687316895, 0.0053400397300720215, 0.005659997463226318, 0.006680011749267578, 0.003020048141479492, 0.0039000511169433594, 0.004280030727386475, 0.0051400065422058105, 0.002980053424835205, 0.006060004234313965, 0.0034800171852111816, 0.00363999605178833, 0.005380034446716309, 0.004680037498474121, 0.0040400028228759766, 0.006460011005401611, 0.0065400004386901855, 0.007520020008087158, 0.005920052528381348, 0.007480025291442871, 0.005520045757293701, 0.005840003490447998, 0.004860043525695801, 0.0051000118255615234, 0.0029399991035461426, 0.0075800418853759766, 0.00868004560470581, 0.005020022392272949, 0.00448000431060791, 0.008240044116973877, 0.005000054836273193, 0.00952005386352539, 0.005600035190582275, 0.006080031394958496, 0.005800008773803711, 0.005120038986206055, 0.0051400065422058105]\n",
            "\n",
            "\n",
            "e1_test:  [0.9736000299453735, 0.9398999810218811, 0.906499981880188, 0.8587999939918518, 0.8154000043869019, 0.7792999744415283, 0.7468000054359436, 0.7168999910354614, 0.7059000134468079, 0.6669000387191772, 0.6276999711990356, 0.6134999990463257, 0.6067000031471252, 0.586400032043457, 0.565500020980835, 0.5626000165939331, 0.5341000556945801, 0.5242000222206116, 0.5250999927520752, 0.5204000473022461, 0.5082000494003296, 0.49880003929138184, 0.4952000379562378, 0.4941999912261963, 0.4943000078201294, 0.47439998388290405, 0.4812999963760376, 0.48409998416900635, 0.48409998416900635, 0.43480002880096436, 0.43529999256134033, 0.43340003490448, 0.43140000104904175, 0.4336000084877014, 0.43220001459121704, 0.43470001220703125, 0.4358000159263611, 0.435699999332428, 0.4384000301361084, 0.44270002841949463, 0.4376000165939331, 0.43650001287460327, 0.4359999895095825, 0.43860000371932983, 0.43639999628067017, 0.4415000081062317, 0.43790000677108765, 0.43779999017715454, 0.43320000171661377, 0.444100022315979, 0.4431999921798706, 0.435699999332428, 0.43860000371932983, 0.43970000743865967, 0.4369000196456909, 0.4384000301361084, 0.44209998846054077, 0.4406999945640564, 0.43870002031326294, 0.43290001153945923, 0.4345000386238098, 0.43459999561309814, 0.43480002880096436, 0.43790000677108765, 0.43779999017715454, 0.4316999912261963, 0.43480002880096436, 0.43389999866485596, 0.4311000108718872, 0.43470001220703125, 0.4336000084877014, 0.4359999895095825, 0.4351000189781189, 0.4361000061035156, 0.4327000379562378, 0.4348999857902527, 0.4327999949455261, 0.43230003118515015, 0.4313000440597534, 0.4326000213623047, 0.43400001525878906, 0.435200035572052, 0.4333000183105469, 0.4345000386238098, 0.43309998512268066, 0.43540000915527344, 0.4338000416755676, 0.4316999912261963, 0.4325000047683716, 0.43560004234313965, 0.43650001287460327, 0.4336000084877014, 0.4334999918937683, 0.43630003929138184, 0.43340003490448, 0.4366000294685364, 0.43459999561309814, 0.43410003185272217, 0.4341999888420105, 0.43410003185272217, 0.4318000078201294]\n",
            "e5_test:  [0.8852999806404114, 0.7960000038146973, 0.6897000074386597, 0.6100000143051147, 0.5422999858856201, 0.49000000953674316, 0.45270001888275146, 0.40420001745224, 0.38679999113082886, 0.3539000153541565, 0.30980002880096436, 0.29809999465942383, 0.29030001163482666, 0.2700999975204468, 0.2559000253677368, 0.24900001287460327, 0.24070000648498535, 0.22550004720687866, 0.23070001602172852, 0.22190004587173462, 0.21729999780654907, 0.21480000019073486, 0.20899999141693115, 0.20910000801086426, 0.2069000005722046, 0.1940000057220459, 0.20680004358291626, 0.20320004224777222, 0.20109999179840088, 0.164900004863739, 0.16790002584457397, 0.16920000314712524, 0.16620004177093506, 0.16830003261566162, 0.16930001974105835, 0.169700026512146, 0.1721000075340271, 0.16910004615783691, 0.17450004816055298, 0.17770004272460938, 0.1754000186920166, 0.17500001192092896, 0.17379999160766602, 0.1788000464439392, 0.17669999599456787, 0.18029999732971191, 0.17750000953674316, 0.18150001764297485, 0.18040001392364502, 0.18209999799728394, 0.18370002508163452, 0.18029999732971191, 0.18300002813339233, 0.17890000343322754, 0.1850000023841858, 0.18340003490447998, 0.1811000108718872, 0.18810003995895386, 0.1811000108718872, 0.17739999294281006, 0.17890000343322754, 0.17710000276565552, 0.18010002374649048, 0.18320000171661377, 0.18090003728866577, 0.18029999732971191, 0.1787000298500061, 0.18000000715255737, 0.17500001192092896, 0.17720001935958862, 0.1779000163078308, 0.17830002307891846, 0.17430001497268677, 0.1811000108718872, 0.17840003967285156, 0.17820000648498535, 0.18160003423690796, 0.17810004949569702, 0.17750000953674316, 0.18209999799728394, 0.18070000410079956, 0.18400001525878906, 0.18140000104904175, 0.1827000379562378, 0.18150001764297485, 0.18050003051757812, 0.18000000715255737, 0.1816999912261963, 0.1784999966621399, 0.18300002813339233, 0.185200035572052, 0.18020004034042358, 0.17720001935958862, 0.18490004539489746, 0.1809999942779541, 0.18610000610351562, 0.1809999942779541, 0.1819000244140625, 0.17990005016326904, 0.18160003423690796, 0.1809999942779541]\n",
            "\n",
            "\n",
            "TIME:  10638.012291\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n",
            "Namespace(arch='cbam_resnet50', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 4.388 | top1-e-train: 0.882, top5-e-train: 0.640 | top1-e-test: 0.877, top5-e-test: 0.627\n",
            "[Epoch   1], lr: 0.10000, Loss: 3.374 | top1-e-train: 0.765, top5-e-train: 0.460 | top1-e-test: 0.745, top5-e-test: 0.438\n",
            "[Epoch   2], lr: 0.10000, Loss: 2.851 | top1-e-train: 0.709, top5-e-train: 0.389 | top1-e-test: 0.707, top5-e-test: 0.385\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.483 | top1-e-train: 0.608, top5-e-train: 0.281 | top1-e-test: 0.612, top5-e-test: 0.292\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.218 | top1-e-train: 0.582, top5-e-train: 0.258 | top1-e-test: 0.585, top5-e-test: 0.268\n",
            "[Epoch   5], lr: 0.10000, Loss: 2.023 | top1-e-train: 0.536, top5-e-train: 0.218 | top1-e-test: 0.558, top5-e-test: 0.243\n",
            "[Epoch   6], lr: 0.10000, Loss: 1.855 | top1-e-train: 0.468, top5-e-train: 0.164 | top1-e-test: 0.510, top5-e-test: 0.205\n",
            "[Epoch   7], lr: 0.10000, Loss: 1.715 | top1-e-train: 0.453, top5-e-train: 0.155 | top1-e-test: 0.508, top5-e-test: 0.205\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.582 | top1-e-train: 0.421, top5-e-train: 0.132 | top1-e-test: 0.485, top5-e-test: 0.188\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.471 | top1-e-train: 0.379, top5-e-train: 0.107 | top1-e-test: 0.458, top5-e-test: 0.172\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.367 | top1-e-train: 0.372, top5-e-train: 0.102 | top1-e-test: 0.462, top5-e-test: 0.180\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.268 | top1-e-train: 0.342, top5-e-train: 0.086 | top1-e-test: 0.454, top5-e-test: 0.165\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.169 | top1-e-train: 0.328, top5-e-train: 0.077 | top1-e-test: 0.444, top5-e-test: 0.166\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.075 | top1-e-train: 0.267, top5-e-train: 0.052 | top1-e-test: 0.431, top5-e-test: 0.158\n",
            "[Epoch  14], lr: 0.10000, Loss: 0.999 | top1-e-train: 0.258, top5-e-train: 0.048 | top1-e-test: 0.431, top5-e-test: 0.159\n",
            "[Epoch  15], lr: 0.10000, Loss: 0.898 | top1-e-train: 0.248, top5-e-train: 0.043 | top1-e-test: 0.432, top5-e-test: 0.155\n",
            "[Epoch  16], lr: 0.10000, Loss: 0.825 | top1-e-train: 0.209, top5-e-train: 0.031 | top1-e-test: 0.415, top5-e-test: 0.154\n",
            "[Epoch  17], lr: 0.10000, Loss: 0.756 | top1-e-train: 0.223, top5-e-train: 0.032 | top1-e-test: 0.436, top5-e-test: 0.161\n",
            "[Epoch  18], lr: 0.10000, Loss: 0.686 | top1-e-train: 0.183, top5-e-train: 0.021 | top1-e-test: 0.424, top5-e-test: 0.155\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.607 | top1-e-train: 0.144, top5-e-train: 0.013 | top1-e-test: 0.411, top5-e-test: 0.144\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.549 | top1-e-train: 0.144, top5-e-train: 0.013 | top1-e-test: 0.418, top5-e-test: 0.155\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.495 | top1-e-train: 0.135, top5-e-train: 0.009 | top1-e-test: 0.423, top5-e-test: 0.152\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.437 | top1-e-train: 0.107, top5-e-train: 0.007 | top1-e-test: 0.407, top5-e-test: 0.152\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.383 | top1-e-train: 0.120, top5-e-train: 0.008 | top1-e-test: 0.420, top5-e-test: 0.156\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.337 | top1-e-train: 0.089, top5-e-train: 0.004 | top1-e-test: 0.407, top5-e-test: 0.152\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.308 | top1-e-train: 0.079, top5-e-train: 0.003 | top1-e-test: 0.406, top5-e-test: 0.155\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.265 | top1-e-train: 0.070, top5-e-train: 0.003 | top1-e-test: 0.403, top5-e-test: 0.152\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.237 | top1-e-train: 0.067, top5-e-train: 0.003 | top1-e-test: 0.409, top5-e-test: 0.153\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.211 | top1-e-train: 0.059, top5-e-train: 0.002 | top1-e-test: 0.407, top5-e-test: 0.154\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.104 | top1-e-train: 0.015, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.133\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.067 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.128\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.054 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.369, top5-e-test: 0.128\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.049 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.368, top5-e-test: 0.128\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.041 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.128\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.129\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.034 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.127\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}