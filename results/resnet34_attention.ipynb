{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet34_attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenvietan/DL_Attention_PA1_ee898/blob/master/resnet34_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZURFpiuM8XVU",
        "colab_type": "code",
        "outputId": "906ec357-eb86-4117-ae05-67a6541dec7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8265
        }
      },
      "source": [
        "!bash run_all_34.sh\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(arch='resnet34', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 4.007 | top1-e-train: 0.871, top5-e-train: 0.625 | top1-e-test: 0.857, top5-e-test: 0.600\n",
            "[Epoch   1], lr: 0.10000, Loss: 3.307 | top1-e-train: 0.778, top5-e-train: 0.465 | top1-e-test: 0.766, top5-e-test: 0.451\n",
            "[Epoch   2], lr: 0.10000, Loss: 2.917 | top1-e-train: 0.754, top5-e-train: 0.455 | top1-e-test: 0.750, top5-e-test: 0.467\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.614 | top1-e-train: 0.661, top5-e-train: 0.336 | top1-e-test: 0.671, top5-e-test: 0.346\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.358 | top1-e-train: 0.604, top5-e-train: 0.273 | top1-e-test: 0.617, top5-e-test: 0.289\n",
            "[Epoch   5], lr: 0.10000, Loss: 2.160 | top1-e-train: 0.583, top5-e-train: 0.257 | top1-e-test: 0.583, top5-e-test: 0.267\n",
            "[Epoch   6], lr: 0.10000, Loss: 1.995 | top1-e-train: 0.520, top5-e-train: 0.206 | top1-e-test: 0.546, top5-e-test: 0.239\n",
            "[Epoch   7], lr: 0.10000, Loss: 1.874 | top1-e-train: 0.498, top5-e-train: 0.191 | top1-e-test: 0.532, top5-e-test: 0.228\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.748 | top1-e-train: 0.467, top5-e-train: 0.163 | top1-e-test: 0.513, top5-e-test: 0.210\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.672 | top1-e-train: 0.470, top5-e-train: 0.164 | top1-e-test: 0.531, top5-e-test: 0.223\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.568 | top1-e-train: 0.437, top5-e-train: 0.146 | top1-e-test: 0.502, top5-e-test: 0.200\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.462 | top1-e-train: 0.405, top5-e-train: 0.118 | top1-e-test: 0.486, top5-e-test: 0.193\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.379 | top1-e-train: 0.375, top5-e-train: 0.098 | top1-e-test: 0.476, top5-e-test: 0.178\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.303 | top1-e-train: 0.342, top5-e-train: 0.087 | top1-e-test: 0.453, top5-e-test: 0.170\n",
            "[Epoch  14], lr: 0.10000, Loss: 1.212 | top1-e-train: 0.313, top5-e-train: 0.073 | top1-e-test: 0.443, top5-e-test: 0.164\n",
            "[Epoch  15], lr: 0.10000, Loss: 1.150 | top1-e-train: 0.320, top5-e-train: 0.074 | top1-e-test: 0.455, top5-e-test: 0.172\n",
            "[Epoch  16], lr: 0.10000, Loss: 1.067 | top1-e-train: 0.293, top5-e-train: 0.060 | top1-e-test: 0.434, top5-e-test: 0.156\n",
            "[Epoch  17], lr: 0.10000, Loss: 0.999 | top1-e-train: 0.286, top5-e-train: 0.056 | top1-e-test: 0.449, top5-e-test: 0.173\n",
            "[Epoch  18], lr: 0.10000, Loss: 0.928 | top1-e-train: 0.259, top5-e-train: 0.051 | top1-e-test: 0.442, top5-e-test: 0.167\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.874 | top1-e-train: 0.229, top5-e-train: 0.037 | top1-e-test: 0.429, top5-e-test: 0.161\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.804 | top1-e-train: 0.213, top5-e-train: 0.029 | top1-e-test: 0.429, top5-e-test: 0.159\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.743 | top1-e-train: 0.223, top5-e-train: 0.033 | top1-e-test: 0.437, top5-e-test: 0.167\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.685 | top1-e-train: 0.183, top5-e-train: 0.022 | top1-e-test: 0.419, top5-e-test: 0.151\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.628 | top1-e-train: 0.182, top5-e-train: 0.020 | top1-e-test: 0.435, top5-e-test: 0.160\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.581 | top1-e-train: 0.172, top5-e-train: 0.021 | top1-e-test: 0.430, top5-e-test: 0.167\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.539 | top1-e-train: 0.133, top5-e-train: 0.010 | top1-e-test: 0.414, top5-e-test: 0.157\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.488 | top1-e-train: 0.124, top5-e-train: 0.009 | top1-e-test: 0.414, top5-e-test: 0.154\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.446 | top1-e-train: 0.152, top5-e-train: 0.015 | top1-e-test: 0.433, top5-e-test: 0.169\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.416 | top1-e-train: 0.109, top5-e-train: 0.007 | top1-e-test: 0.424, top5-e-test: 0.157\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.209 | top1-e-train: 0.038, top5-e-train: 0.002 | top1-e-test: 0.386, top5-e-test: 0.138\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.147 | top1-e-train: 0.030, top5-e-train: 0.001 | top1-e-test: 0.388, top5-e-test: 0.137\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.115 | top1-e-train: 0.025, top5-e-train: 0.001 | top1-e-test: 0.387, top5-e-test: 0.139\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.100 | top1-e-train: 0.021, top5-e-train: 0.001 | top1-e-test: 0.386, top5-e-test: 0.137\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.093 | top1-e-train: 0.019, top5-e-train: 0.000 | top1-e-test: 0.387, top5-e-test: 0.137\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.081 | top1-e-train: 0.018, top5-e-train: 0.001 | top1-e-test: 0.386, top5-e-test: 0.141\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.075 | top1-e-train: 0.015, top5-e-train: 0.000 | top1-e-test: 0.388, top5-e-test: 0.138\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.068 | top1-e-train: 0.014, top5-e-train: 0.001 | top1-e-test: 0.387, top5-e-test: 0.139\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.063 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.385, top5-e-test: 0.138\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.058 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.386, top5-e-test: 0.138\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.052 | top1-e-train: 0.010, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.135\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.051 | top1-e-train: 0.009, top5-e-train: 0.000 | top1-e-test: 0.384, top5-e-test: 0.138\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.046 | top1-e-train: 0.009, top5-e-train: 0.001 | top1-e-test: 0.387, top5-e-test: 0.138\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.044 | top1-e-train: 0.009, top5-e-train: 0.000 | top1-e-test: 0.388, top5-e-test: 0.137\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.041 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.384, top5-e-test: 0.136\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.039 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.139\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.135\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.036 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.136\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.033 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.135\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.032 | top1-e-train: 0.007, top5-e-train: 0.001 | top1-e-test: 0.381, top5-e-test: 0.137\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.030 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.385, top5-e-test: 0.138\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.029 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.384, top5-e-test: 0.136\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.028 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.137\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.028 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.138\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.026 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.384, top5-e-test: 0.137\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.384, top5-e-test: 0.136\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.026 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.381, top5-e-test: 0.135\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.134\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.134\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.021 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.135\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.019 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.134\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.018 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.134\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.132\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.133\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.133\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.134\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.133\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.136\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.133\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.135\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.135\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.136\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.136\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.135\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.135\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.134\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.135\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.134\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.135\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.136\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.135\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.134\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.133\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.134\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.136\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.135\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.136\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.136\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.137\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.135\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.375, top5-e-test: 0.136\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.134\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.134\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.135\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.135\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.134\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.134\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.135\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.136\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.137\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.136\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.004, top5-e-train: 0.001 | top1-e-test: 0.381, top5-e-test: 0.136\n",
            "--------- Finish Training --------\n",
            "Top1E:  0.375200033188\n",
            "Top5E:  0.13220000267\n",
            "\n",
            "\n",
            "e1_train:  [0.8711000084877014, 0.7777000069618225, 0.7541800141334534, 0.6612399816513062, 0.6036200523376465, 0.5833799839019775, 0.5196200013160706, 0.4981600046157837, 0.46737998723983765, 0.4696199893951416, 0.4369400143623352, 0.40487998723983765, 0.37540000677108765, 0.34220004081726074, 0.3133600354194641, 0.3200399875640869, 0.2928600311279297, 0.2862400412559509, 0.25880002975463867, 0.2291000485420227, 0.21277999877929688, 0.2232600450515747, 0.18306005001068115, 0.18213999271392822, 0.1722000241279602, 0.1329200267791748, 0.12389999628067017, 0.15244001150131226, 0.1091800332069397, 0.03798002004623413, 0.02954000234603882, 0.024800002574920654, 0.021060049533843994, 0.01930004358291626, 0.017540037631988525, 0.015080034732818604, 0.01416003704071045, 0.011320054531097412, 0.010839998722076416, 0.010179996490478516, 0.008920013904571533, 0.009280025959014893, 0.008640050888061523, 0.007700026035308838, 0.006820023059844971, 0.006680011749267578, 0.006820023059844971, 0.005180001258850098, 0.007380008697509766, 0.005540013313293457, 0.004220008850097656, 0.005060017108917236, 0.003859996795654297, 0.005000054836273193, 0.005360007286071777, 0.00448000431060791, 0.0031000375747680664, 0.003980040550231934, 0.004180014133453369, 0.0030600428581237793, 0.003920018672943115, 0.0025600194931030273, 0.002160012722015381, 0.002499997615814209, 0.0028800368309020996, 0.0027600526809692383, 0.0028200149536132812, 0.0025400519371032715, 0.004220008850097656, 0.003320038318634033, 0.0037000179290771484, 0.003240048885345459, 0.0025800466537475586, 0.002140045166015625, 0.0018000006675720215, 0.0027600526809692383, 0.0022200345993041992, 0.002180039882659912, 0.002740025520324707, 0.0019600391387939453, 0.001980006694793701, 0.0018000006675720215, 0.0020599961280822754, 0.0023000240325927734, 0.0017200112342834473, 0.0015600323677062988, 0.0029399991035461426, 0.002499997615814209, 0.0016200542449951172, 0.0021200180053710938, 0.0018600225448608398, 0.0023200511932373047, 0.0020599961280822754, 0.0026200413703918457, 0.002240002155303955, 0.0019600391387939453, 0.0019200444221496582, 0.0020200014114379883, 0.0026000142097473145, 0.001940011978149414, 0.003560006618499756]\n",
            "e5_train:  [0.6247400045394897, 0.46512001752853394, 0.4551200270652771, 0.3361999988555908, 0.273360013961792, 0.25745999813079834, 0.20594000816345215, 0.19110000133514404, 0.16290003061294556, 0.16434001922607422, 0.14562004804611206, 0.11826002597808838, 0.09800004959106445, 0.08678001165390015, 0.0728600025177002, 0.0740399956703186, 0.06006002426147461, 0.05626004934310913, 0.05121999979019165, 0.036640048027038574, 0.02922004461288452, 0.033460021018981934, 0.02228003740310669, 0.01987999677658081, 0.02096003293991089, 0.010000050067901611, 0.008800029754638672, 0.015220046043395996, 0.006760001182556152, 0.0016200542449951172, 0.0009199976921081543, 0.0010200142860412598, 0.0010600090026855469, 0.0004799962043762207, 0.000800013542175293, 0.00020003318786621094, 0.0007600188255310059, 0.0002599954605102539, 0.0003000497817993164, 0.0002599954605102539, 0.0001800060272216797, 0.0005400180816650391, 0.00010001659393310547, 0.00010001659393310547, 6.002187728881836e-05, 6.002187728881836e-05, 0.00010001659393310547, 6.002187728881836e-05, 0.000500023365020752, 0.00010001659393310547, 2.002716064453125e-05, 0.00016003847122192383, 0.0, 0.0003600120544433594, 0.00010001659393310547, 0.00012004375457763672, 8.004903793334961e-05, 0.00016003847122192383, 0.0003400444984436035, 4.00543212890625e-05, 0.0003400444984436035, 2.002716064453125e-05, 4.00543212890625e-05, 4.00543212890625e-05, 0.00014001131057739258, 8.004903793334961e-05, 4.00543212890625e-05, 6.002187728881836e-05, 0.0004400014877319336, 0.0003400444984436035, 0.0004400014877319336, 0.0002200007438659668, 6.002187728881836e-05, 6.002187728881836e-05, 4.00543212890625e-05, 0.00010001659393310547, 0.0, 2.002716064453125e-05, 8.004903793334961e-05, 2.002716064453125e-05, 0.0, 0.0, 8.004903793334961e-05, 8.004903793334961e-05, 0.0, 2.002716064453125e-05, 0.00024002790451049805, 0.0003800392150878906, 0.0, 4.00543212890625e-05, 0.0, 0.00014001131057739258, 4.00543212890625e-05, 0.0002200007438659668, 6.002187728881836e-05, 2.002716064453125e-05, 0.00012004375457763672, 2.002716064453125e-05, 0.0001800060272216797, 2.002716064453125e-05, 0.0005600452423095703]\n",
            "\n",
            "\n",
            "e1_test:  [0.8565000295639038, 0.7662000060081482, 0.749500036239624, 0.6707000136375427, 0.6168999671936035, 0.5830000042915344, 0.5458999872207642, 0.5321000218391418, 0.5127000212669373, 0.531000018119812, 0.5015000104904175, 0.4862000346183777, 0.47610002756118774, 0.45270001888275146, 0.44279998540878296, 0.45500004291534424, 0.4337000250816345, 0.4491000175476074, 0.44190001487731934, 0.42910003662109375, 0.4294000267982483, 0.43720000982284546, 0.41870003938674927, 0.43540000915527344, 0.430400013923645, 0.4142000079154968, 0.4140999913215637, 0.4325000047683716, 0.42419999837875366, 0.38590002059936523, 0.3878999948501587, 0.38679999113082886, 0.3856000304222107, 0.38690000772476196, 0.3862000107765198, 0.38760000467300415, 0.3865000009536743, 0.38530004024505615, 0.38609999418258667, 0.3830000162124634, 0.38370001316070557, 0.38690000772476196, 0.3881000280380249, 0.38359999656677246, 0.3824999928474426, 0.38260000944137573, 0.3824999928474426, 0.3823000192642212, 0.3813999891281128, 0.38460004329681396, 0.38350003957748413, 0.38020002841949463, 0.38190001249313354, 0.38380002975463867, 0.38380002975463867, 0.38050001859664917, 0.3817000389099121, 0.3815000057220459, 0.382099986076355, 0.38200002908706665, 0.38020002841949463, 0.3788999915122986, 0.3791000247001648, 0.37720000743865967, 0.38020002841949463, 0.3774000406265259, 0.37950003147125244, 0.3785000443458557, 0.3788999915122986, 0.37959998846054077, 0.38179999589920044, 0.3783000111579895, 0.37790000438690186, 0.3788999915122986, 0.376800000667572, 0.37860000133514404, 0.37810003757476807, 0.37779998779296875, 0.37790000438690186, 0.3763999938964844, 0.3777000308036804, 0.37790000438690186, 0.3792000412940979, 0.3784000277519226, 0.3777000308036804, 0.3790000081062317, 0.3797000050544739, 0.37929999828338623, 0.3774000406265259, 0.3752000331878662, 0.3776000142097473, 0.37940001487731934, 0.37620002031326294, 0.3763999938964844, 0.3767000436782837, 0.3783000111579895, 0.37800002098083496, 0.3767000436782837, 0.3781999945640564, 0.37630003690719604, 0.3806000351905823]\n",
            "e5_test:  [0.5997999906539917, 0.45090001821517944, 0.46670001745224, 0.34640002250671387, 0.2889000177383423, 0.26740002632141113, 0.23930001258850098, 0.2282000184059143, 0.20990002155303955, 0.22310000658035278, 0.20030003786087036, 0.19310003519058228, 0.1784999966621399, 0.1696000099182129, 0.16350001096725464, 0.1721000075340271, 0.15640002489089966, 0.1728000044822693, 0.1672000288963318, 0.16089999675750732, 0.1593000292778015, 0.16690003871917725, 0.15140002965927124, 0.1599000096321106, 0.16699999570846558, 0.1567000150680542, 0.15410000085830688, 0.16920000314712524, 0.15700000524520874, 0.138200044631958, 0.13700002431869507, 0.1388000249862671, 0.13670003414154053, 0.13700002431869507, 0.14079999923706055, 0.13840001821517944, 0.13920003175735474, 0.13750004768371582, 0.13840001821517944, 0.13530004024505615, 0.13760000467300415, 0.13750004768371582, 0.13690000772476196, 0.1357000470161438, 0.1388000249862671, 0.1350000500679016, 0.1355000138282776, 0.13530004024505615, 0.1371999979019165, 0.13750004768371582, 0.13600003719329834, 0.13700002431869507, 0.13750004768371582, 0.13660001754760742, 0.13630002737045288, 0.13520002365112305, 0.13420003652572632, 0.1340000033378601, 0.13450002670288086, 0.13370001316070557, 0.13390004634857178, 0.13220000267028809, 0.13310003280639648, 0.13300001621246338, 0.1341000199317932, 0.13340002298355103, 0.13600003719329834, 0.1332000494003296, 0.13539999723434448, 0.1349000334739685, 0.1356000304222107, 0.13580000400543213, 0.13460004329681396, 0.1349000334739685, 0.13420003652572632, 0.13450002670288086, 0.13420003652572632, 0.13510000705718994, 0.1357000470161438, 0.1348000168800354, 0.13390004634857178, 0.13310003280639648, 0.1341000199317932, 0.13600003719329834, 0.13450002670288086, 0.13630002737045288, 0.13600003719329834, 0.13710004091262817, 0.13530004024505615, 0.1355000138282776, 0.13420003652572632, 0.13429999351501465, 0.13450002670288086, 0.1350000500679016, 0.13390004634857178, 0.13370001316070557, 0.13450002670288086, 0.1355000138282776, 0.13670003414154053, 0.13600003719329834, 0.13620001077651978]\n",
            "\n",
            "\n",
            "TIME:  6749.21091914\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n",
            "Namespace(arch='se_resnet34', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 3.874 | top1-e-train: 0.832, top5-e-train: 0.552 | top1-e-test: 0.825, top5-e-test: 0.541\n",
            "[Epoch   1], lr: 0.10000, Loss: 3.160 | top1-e-train: 0.799, top5-e-train: 0.527 | top1-e-test: 0.775, top5-e-test: 0.491\n",
            "[Epoch   2], lr: 0.10000, Loss: 2.789 | top1-e-train: 0.688, top5-e-train: 0.371 | top1-e-test: 0.689, top5-e-test: 0.375\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.495 | top1-e-train: 0.602, top5-e-train: 0.274 | top1-e-test: 0.615, top5-e-test: 0.293\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.234 | top1-e-train: 0.568, top5-e-train: 0.243 | top1-e-test: 0.582, top5-e-test: 0.265\n",
            "[Epoch   5], lr: 0.10000, Loss: 2.107 | top1-e-train: 0.518, top5-e-train: 0.204 | top1-e-test: 0.547, top5-e-test: 0.233\n",
            "[Epoch   6], lr: 0.10000, Loss: 1.972 | top1-e-train: 0.501, top5-e-train: 0.188 | top1-e-test: 0.534, top5-e-test: 0.226\n",
            "[Epoch   7], lr: 0.10000, Loss: 1.804 | top1-e-train: 0.481, top5-e-train: 0.172 | top1-e-test: 0.527, top5-e-test: 0.215\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.675 | top1-e-train: 0.448, top5-e-train: 0.146 | top1-e-test: 0.502, top5-e-test: 0.195\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.564 | top1-e-train: 0.417, top5-e-train: 0.125 | top1-e-test: 0.489, top5-e-test: 0.189\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.456 | top1-e-train: 0.407, top5-e-train: 0.123 | top1-e-test: 0.493, top5-e-test: 0.198\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.365 | top1-e-train: 0.380, top5-e-train: 0.106 | top1-e-test: 0.477, top5-e-test: 0.187\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.275 | top1-e-train: 0.341, top5-e-train: 0.085 | top1-e-test: 0.456, top5-e-test: 0.171\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.198 | top1-e-train: 0.322, top5-e-train: 0.074 | top1-e-test: 0.452, top5-e-test: 0.168\n",
            "[Epoch  14], lr: 0.10000, Loss: 1.116 | top1-e-train: 0.290, top5-e-train: 0.060 | top1-e-test: 0.436, top5-e-test: 0.159\n",
            "[Epoch  15], lr: 0.10000, Loss: 1.039 | top1-e-train: 0.265, top5-e-train: 0.052 | top1-e-test: 0.435, top5-e-test: 0.158\n",
            "[Epoch  16], lr: 0.10000, Loss: 0.970 | top1-e-train: 0.256, top5-e-train: 0.044 | top1-e-test: 0.431, top5-e-test: 0.164\n",
            "[Epoch  17], lr: 0.10000, Loss: 0.904 | top1-e-train: 0.242, top5-e-train: 0.041 | top1-e-test: 0.440, top5-e-test: 0.164\n",
            "[Epoch  18], lr: 0.10000, Loss: 0.842 | top1-e-train: 0.226, top5-e-train: 0.034 | top1-e-test: 0.437, top5-e-test: 0.162\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.761 | top1-e-train: 0.208, top5-e-train: 0.027 | top1-e-test: 0.439, top5-e-test: 0.167\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.702 | top1-e-train: 0.186, top5-e-train: 0.022 | top1-e-test: 0.428, top5-e-test: 0.162\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.649 | top1-e-train: 0.173, top5-e-train: 0.018 | top1-e-test: 0.431, top5-e-test: 0.163\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.602 | top1-e-train: 0.161, top5-e-train: 0.016 | top1-e-test: 0.438, top5-e-test: 0.163\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.547 | top1-e-train: 0.136, top5-e-train: 0.011 | top1-e-test: 0.419, top5-e-test: 0.161\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.493 | top1-e-train: 0.125, top5-e-train: 0.010 | top1-e-test: 0.420, top5-e-test: 0.153\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.447 | top1-e-train: 0.123, top5-e-train: 0.008 | top1-e-test: 0.429, top5-e-test: 0.159\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.416 | top1-e-train: 0.105, top5-e-train: 0.006 | top1-e-test: 0.420, top5-e-test: 0.161\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.372 | top1-e-train: 0.099, top5-e-train: 0.005 | top1-e-test: 0.425, top5-e-test: 0.161\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.337 | top1-e-train: 0.091, top5-e-train: 0.005 | top1-e-test: 0.420, top5-e-test: 0.160\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.174 | top1-e-train: 0.028, top5-e-train: 0.001 | top1-e-test: 0.389, top5-e-test: 0.142\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.113 | top1-e-train: 0.020, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.141\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.091 | top1-e-train: 0.017, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.145\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.078 | top1-e-train: 0.013, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.142\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.068 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.141\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.061 | top1-e-train: 0.010, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.141\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.058 | top1-e-train: 0.010, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.052 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.141\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.048 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.044 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.140\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.040 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.139\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.039 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.140\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.034 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.033 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.032 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.141\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.029 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.139\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.030 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.141\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.028 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.139\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.026 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.138\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.023 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.139\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.023 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.140\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.021 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.141\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.020 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.141\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.019 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.140\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.018 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.140\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.018 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.141\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.140\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.143\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.141\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.141\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.141\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.142\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.141\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.141\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.140\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.140\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.141\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.141\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.141\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.140\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.142\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.141\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.141\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.141\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.142\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.140\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.141\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.142\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.141\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.140\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.139\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.141\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.140\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.141\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.141\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.141\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.140\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.141\n",
            "--------- Finish Training --------\n",
            "Top1E:  0.375500023365\n",
            "Top5E:  0.137800037861\n",
            "\n",
            "\n",
            "e1_train:  [0.8318799734115601, 0.7985199689865112, 0.688040018081665, 0.6023600101470947, 0.5675400495529175, 0.5183800458908081, 0.5010000467300415, 0.480679988861084, 0.44808000326156616, 0.4165800213813782, 0.4067400097846985, 0.3800399899482727, 0.3414199948310852, 0.3215799927711487, 0.2895600199699402, 0.26544004678726196, 0.2563199996948242, 0.2417200207710266, 0.22620004415512085, 0.20778000354766846, 0.1858600378036499, 0.17278003692626953, 0.16104000806808472, 0.1359800100326538, 0.1252000331878662, 0.1228400468826294, 0.10536003112792969, 0.0987200140953064, 0.09148001670837402, 0.027960002422332764, 0.019700050354003906, 0.017240047454833984, 0.013420045375823975, 0.01118004322052002, 0.0098000168800354, 0.009580016136169434, 0.008379995822906494, 0.007560014724731445, 0.006660044193267822, 0.00568002462387085, 0.006020009517669678, 0.005720019340515137, 0.0045400261878967285, 0.004880011081695557, 0.004739999771118164, 0.0036800503730773926, 0.003920018672943115, 0.0037200450897216797, 0.0035400390625, 0.003340005874633789, 0.0029399991035461426, 0.00270003080368042, 0.0028600096702575684, 0.0028800368309020996, 0.002499997615814209, 0.0020200014114379883, 0.0023200511932373047, 0.0017000436782836914, 0.0018000006675720215, 0.0020599961280822754, 0.0019600391387939453, 0.001940011978149414, 0.0017200112342834473, 0.0015400052070617676, 0.0017600059509277344, 0.0014600157737731934, 0.001880049705505371, 0.0015799999237060547, 0.0015400052070617676, 0.0016600489616394043, 0.0013599991798400879, 0.0016800165176391602, 0.0016800165176391602, 0.0014800429344177246, 0.0016600489616394043, 0.001640021800994873, 0.001840054988861084, 0.0015799999237060547, 0.0013800263404846191, 0.0012800097465515137, 0.0014200210571289062, 0.0014800429344177246, 0.0013599991798400879, 0.0014800429344177246, 0.0013800263404846191, 0.0015000104904174805, 0.0015400052070617676, 0.0013800263404846191, 0.0011200308799743652, 0.0011600255966186523, 0.0014600157737731934, 0.001040041446685791, 0.0010600090026855469, 0.0014600157737731934, 0.0013800263404846191, 0.0012400150299072266, 0.0011600255966186523, 0.0013599991798400879, 0.0012200474739074707, 0.001300036907196045, 0.0012200474739074707]\n",
            "e5_train:  [0.5522800087928772, 0.5268000364303589, 0.3711000084877014, 0.2742000222206116, 0.24300003051757812, 0.20418000221252441, 0.18794000148773193, 0.1715800166130066, 0.14564001560211182, 0.12480002641677856, 0.12288004159927368, 0.10566002130508423, 0.08524000644683838, 0.07400000095367432, 0.060259997844696045, 0.052220046520233154, 0.04418003559112549, 0.040859997272491455, 0.033780038356781006, 0.027000010013580322, 0.022060036659240723, 0.017900049686431885, 0.016100049018859863, 0.011140048503875732, 0.00962001085281372, 0.008460044860839844, 0.006360054016113281, 0.005200028419494629, 0.005280017852783203, 0.0005600452423095703, 0.0003800392150878906, 0.0003000497817993164, 0.00014001131057739258, 0.00010001659393310547, 8.004903793334961e-05, 0.00014001131057739258, 8.004903793334961e-05, 6.002187728881836e-05, 8.004903793334961e-05, 0.0, 6.002187728881836e-05, 4.00543212890625e-05, 2.002716064453125e-05, 2.002716064453125e-05, 2.002716064453125e-05, 4.00543212890625e-05, 2.002716064453125e-05, 4.00543212890625e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.002716064453125e-05, 6.002187728881836e-05, 0.0, 0.0, 0.0, 2.002716064453125e-05, 0.0, 0.0, 0.0, 0.0, 2.002716064453125e-05, 0.0, 2.002716064453125e-05, 0.0, 0.0, 2.002716064453125e-05, 0.0, 0.0, 0.0, 0.0, 2.002716064453125e-05, 0.0, 0.0, 4.00543212890625e-05, 0.0, 0.0, 0.0, 2.002716064453125e-05, 2.002716064453125e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.002716064453125e-05, 0.0, 0.0]\n",
            "\n",
            "\n",
            "e1_test:  [0.8252999782562256, 0.7746999859809875, 0.6886000037193298, 0.6151000261306763, 0.5820000171661377, 0.5472999811172485, 0.5338000059127808, 0.5267000198364258, 0.5016000270843506, 0.489300012588501, 0.4926000237464905, 0.4765000343322754, 0.45600003004074097, 0.45190000534057617, 0.43639999628067017, 0.43540000915527344, 0.43059998750686646, 0.43950003385543823, 0.43650001287460327, 0.4391000270843506, 0.4280000329017639, 0.4313000440597534, 0.4384000301361084, 0.4190000295639038, 0.41990000009536743, 0.42910003662109375, 0.4198000431060791, 0.42510002851486206, 0.4204000234603882, 0.38850003480911255, 0.3828999996185303, 0.3815000057220459, 0.38040000200271606, 0.3801000118255615, 0.3815000057220459, 0.3792000412940979, 0.3781999945640564, 0.3784000277519226, 0.3801000118255615, 0.3773000240325928, 0.3790000081062317, 0.37880003452301025, 0.37880003452301025, 0.37860000133514404, 0.38020002841949463, 0.3784000277519226, 0.37959998846054077, 0.37620002031326294, 0.37790000438690186, 0.3799999952316284, 0.379800021648407, 0.37800002098083496, 0.37599998712539673, 0.3785000443458557, 0.37709999084472656, 0.37870001792907715, 0.37940001487731934, 0.376800000667572, 0.3791000247001648, 0.3797000050544739, 0.3799999952316284, 0.37950003147125244, 0.38030004501342773, 0.3797000050544739, 0.37940001487731934, 0.3791000247001648, 0.3783000111579895, 0.3781999945640564, 0.3783000111579895, 0.3783000111579895, 0.3781999945640564, 0.37940001487731934, 0.37929999828338623, 0.37779998779296875, 0.3801000118255615, 0.3783000111579895, 0.37709999084472656, 0.37870001792907715, 0.3763999938964844, 0.3773000240325928, 0.37860000133514404, 0.37800002098083496, 0.37779998779296875, 0.3781999945640564, 0.37550002336502075, 0.37779998779296875, 0.3774000406265259, 0.37700003385543823, 0.376800000667572, 0.3790000081062317, 0.37779998779296875, 0.3776000142097473, 0.3784000277519226, 0.3799000382423401, 0.37810003757476807, 0.3776000142097473, 0.3769000172615051, 0.3773000240325928, 0.37630003690719604, 0.37870001792907715, 0.3784000277519226]\n",
            "e5_test:  [0.5407000184059143, 0.49059998989105225, 0.3751000165939331, 0.29260003566741943, 0.26500004529953003, 0.23340004682540894, 0.22610002756118774, 0.21480000019073486, 0.19530004262924194, 0.18900001049041748, 0.1975000500679016, 0.18690001964569092, 0.17080003023147583, 0.16820001602172852, 0.1593000292778015, 0.15810000896453857, 0.16440004110336304, 0.16409999132156372, 0.16170001029968262, 0.1673000454902649, 0.16200000047683716, 0.16280001401901245, 0.16339999437332153, 0.16050004959106445, 0.1527000069618225, 0.15890002250671387, 0.16110002994537354, 0.16060000658035278, 0.1601000428199768, 0.1420000195503235, 0.1412000060081482, 0.1446000337600708, 0.14180004596710205, 0.14100003242492676, 0.1412000060081482, 0.1388000249862671, 0.140500009059906, 0.13980001211166382, 0.1403999924659729, 0.13899999856948853, 0.1389000415802002, 0.14020001888275146, 0.13850003480911255, 0.13860005140304565, 0.1413000226020813, 0.13920003175735474, 0.14070004224777222, 0.13930004835128784, 0.14030003547668457, 0.13930004835128784, 0.13840001821517944, 0.13780003786087036, 0.13930004835128784, 0.1396999955177307, 0.14070004224777222, 0.14090001583099365, 0.13950002193450928, 0.14020001888275146, 0.1406000256538391, 0.1403999924659729, 0.14259999990463257, 0.14110004901885986, 0.14090001583099365, 0.14079999923706055, 0.14230000972747803, 0.1412000060081482, 0.13950002193450928, 0.13950002193450928, 0.14070004224777222, 0.14030003547668457, 0.1403999924659729, 0.14000004529953003, 0.14010000228881836, 0.14110004901885986, 0.140500009059906, 0.14090001583099365, 0.1403999924659729, 0.14160001277923584, 0.14090001583099365, 0.14090001583099365, 0.14149999618530273, 0.14030003547668457, 0.14170002937316895, 0.13990002870559692, 0.13980001211166382, 0.1403999924659729, 0.140500009059906, 0.14160001277923584, 0.1406000256538391, 0.14010000228881836, 0.13940000534057617, 0.14020001888275146, 0.13990002870559692, 0.14079999923706055, 0.1403999924659729, 0.140500009059906, 0.1414000391960144, 0.14100003242492676, 0.14020001888275146, 0.13920003175735474, 0.14079999923706055]\n",
            "\n",
            "\n",
            "TIME:  7067.66247106\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n",
            "Namespace(arch='bam_resnet34', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 4.271 | top1-e-train: 0.898, top5-e-train: 0.666 | top1-e-test: 0.898, top5-e-test: 0.661\n",
            "[Epoch   1], lr: 0.10000, Loss: 3.519 | top1-e-train: 0.798, top5-e-train: 0.501 | top1-e-test: 0.780, top5-e-test: 0.493\n",
            "[Epoch   2], lr: 0.10000, Loss: 3.074 | top1-e-train: 0.725, top5-e-train: 0.406 | top1-e-test: 0.714, top5-e-test: 0.393\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.748 | top1-e-train: 0.663, top5-e-train: 0.335 | top1-e-test: 0.656, top5-e-test: 0.337\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.483 | top1-e-train: 0.619, top5-e-train: 0.288 | top1-e-test: 0.626, top5-e-test: 0.304\n",
            "[Epoch   5], lr: 0.10000, Loss: 2.270 | top1-e-train: 0.583, top5-e-train: 0.254 | top1-e-test: 0.590, top5-e-test: 0.273\n",
            "[Epoch   6], lr: 0.10000, Loss: 2.094 | top1-e-train: 0.548, top5-e-train: 0.225 | top1-e-test: 0.575, top5-e-test: 0.252\n",
            "[Epoch   7], lr: 0.10000, Loss: 1.950 | top1-e-train: 0.517, top5-e-train: 0.201 | top1-e-test: 0.549, top5-e-test: 0.239\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.822 | top1-e-train: 0.471, top5-e-train: 0.169 | top1-e-test: 0.521, top5-e-test: 0.222\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.711 | top1-e-train: 0.445, top5-e-train: 0.148 | top1-e-test: 0.498, top5-e-test: 0.198\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.612 | top1-e-train: 0.433, top5-e-train: 0.136 | top1-e-test: 0.498, top5-e-test: 0.199\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.518 | top1-e-train: 0.412, top5-e-train: 0.124 | top1-e-test: 0.494, top5-e-test: 0.195\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.420 | top1-e-train: 0.372, top5-e-train: 0.104 | top1-e-test: 0.475, top5-e-test: 0.181\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.360 | top1-e-train: 0.371, top5-e-train: 0.099 | top1-e-test: 0.475, top5-e-test: 0.183\n",
            "[Epoch  14], lr: 0.10000, Loss: 1.327 | top1-e-train: 0.340, top5-e-train: 0.087 | top1-e-test: 0.461, top5-e-test: 0.175\n",
            "[Epoch  15], lr: 0.10000, Loss: 1.229 | top1-e-train: 0.320, top5-e-train: 0.077 | top1-e-test: 0.452, top5-e-test: 0.176\n",
            "[Epoch  16], lr: 0.10000, Loss: 1.139 | top1-e-train: 0.312, top5-e-train: 0.068 | top1-e-test: 0.451, top5-e-test: 0.167\n",
            "[Epoch  17], lr: 0.10000, Loss: 1.064 | top1-e-train: 0.276, top5-e-train: 0.057 | top1-e-test: 0.442, top5-e-test: 0.164\n",
            "[Epoch  18], lr: 0.10000, Loss: 0.986 | top1-e-train: 0.250, top5-e-train: 0.046 | top1-e-test: 0.439, top5-e-test: 0.170\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.925 | top1-e-train: 0.250, top5-e-train: 0.045 | top1-e-test: 0.444, top5-e-test: 0.169\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.857 | top1-e-train: 0.247, top5-e-train: 0.042 | top1-e-test: 0.441, top5-e-test: 0.173\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.799 | top1-e-train: 0.226, top5-e-train: 0.035 | top1-e-test: 0.442, top5-e-test: 0.171\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.728 | top1-e-train: 0.219, top5-e-train: 0.030 | top1-e-test: 0.437, top5-e-test: 0.171\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.800 | top1-e-train: 0.223, top5-e-train: 0.034 | top1-e-test: 0.454, top5-e-test: 0.181\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.646 | top1-e-train: 0.163, top5-e-train: 0.017 | top1-e-test: 0.431, top5-e-test: 0.165\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.601 | top1-e-train: 0.142, top5-e-train: 0.012 | top1-e-test: 0.427, top5-e-test: 0.165\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.525 | top1-e-train: 0.129, top5-e-train: 0.009 | top1-e-test: 0.427, top5-e-test: 0.162\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.485 | top1-e-train: 0.114, top5-e-train: 0.009 | top1-e-test: 0.424, top5-e-test: 0.161\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.459 | top1-e-train: 0.116, top5-e-train: 0.009 | top1-e-test: 0.433, top5-e-test: 0.163\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.240 | top1-e-train: 0.043, top5-e-train: 0.002 | top1-e-test: 0.394, top5-e-test: 0.147\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.168 | top1-e-train: 0.036, top5-e-train: 0.004 | top1-e-test: 0.396, top5-e-test: 0.147\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.141 | top1-e-train: 0.029, top5-e-train: 0.002 | top1-e-test: 0.390, top5-e-test: 0.146\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.129 | top1-e-train: 0.025, top5-e-train: 0.002 | top1-e-test: 0.391, top5-e-test: 0.145\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.112 | top1-e-train: 0.022, top5-e-train: 0.001 | top1-e-test: 0.391, top5-e-test: 0.146\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.099 | top1-e-train: 0.022, top5-e-train: 0.003 | top1-e-test: 0.391, top5-e-test: 0.145\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.092 | top1-e-train: 0.018, top5-e-train: 0.001 | top1-e-test: 0.389, top5-e-test: 0.145\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.085 | top1-e-train: 0.014, top5-e-train: 0.001 | top1-e-test: 0.391, top5-e-test: 0.146\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.079 | top1-e-train: 0.017, top5-e-train: 0.002 | top1-e-test: 0.389, top5-e-test: 0.146\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.072 | top1-e-train: 0.017, top5-e-train: 0.005 | top1-e-test: 0.393, top5-e-test: 0.151\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.066 | top1-e-train: 0.012, top5-e-train: 0.002 | top1-e-test: 0.390, top5-e-test: 0.145\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.063 | top1-e-train: 0.013, top5-e-train: 0.003 | top1-e-test: 0.390, top5-e-test: 0.149\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.060 | top1-e-train: 0.013, top5-e-train: 0.003 | top1-e-test: 0.391, top5-e-test: 0.147\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.056 | top1-e-train: 0.014, top5-e-train: 0.004 | top1-e-test: 0.393, top5-e-test: 0.151\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.051 | top1-e-train: 0.010, top5-e-train: 0.002 | top1-e-test: 0.388, top5-e-test: 0.146\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.050 | top1-e-train: 0.012, top5-e-train: 0.004 | top1-e-test: 0.389, top5-e-test: 0.146\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.048 | top1-e-train: 0.013, top5-e-train: 0.005 | top1-e-test: 0.394, top5-e-test: 0.149\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.044 | top1-e-train: 0.011, top5-e-train: 0.003 | top1-e-test: 0.390, top5-e-test: 0.146\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.041 | top1-e-train: 0.011, top5-e-train: 0.004 | top1-e-test: 0.390, top5-e-test: 0.147\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.009, top5-e-train: 0.003 | top1-e-test: 0.390, top5-e-test: 0.144\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.009, top5-e-train: 0.003 | top1-e-test: 0.392, top5-e-test: 0.147\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.036 | top1-e-train: 0.007, top5-e-train: 0.002 | top1-e-test: 0.387, top5-e-test: 0.145\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.031 | top1-e-train: 0.009, top5-e-train: 0.003 | top1-e-test: 0.390, top5-e-test: 0.147\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.030 | top1-e-train: 0.006, top5-e-train: 0.002 | top1-e-test: 0.389, top5-e-test: 0.146\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.030 | top1-e-train: 0.007, top5-e-train: 0.002 | top1-e-test: 0.387, top5-e-test: 0.146\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.029 | top1-e-train: 0.007, top5-e-train: 0.002 | top1-e-test: 0.387, top5-e-test: 0.146\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.027 | top1-e-train: 0.007, top5-e-train: 0.002 | top1-e-test: 0.386, top5-e-test: 0.148\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.026 | top1-e-train: 0.007, top5-e-train: 0.003 | top1-e-test: 0.388, top5-e-test: 0.148\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.025 | top1-e-train: 0.010, top5-e-train: 0.004 | top1-e-test: 0.391, top5-e-test: 0.147\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.025 | top1-e-train: 0.008, top5-e-train: 0.004 | top1-e-test: 0.390, top5-e-test: 0.151\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.020 | top1-e-train: 0.009, top5-e-train: 0.004 | top1-e-test: 0.387, top5-e-test: 0.149\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.021 | top1-e-train: 0.007, top5-e-train: 0.003 | top1-e-test: 0.385, top5-e-test: 0.149\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.019 | top1-e-train: 0.006, top5-e-train: 0.002 | top1-e-test: 0.384, top5-e-test: 0.148\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.019 | top1-e-train: 0.006, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.146\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.018 | top1-e-train: 0.007, top5-e-train: 0.003 | top1-e-test: 0.385, top5-e-test: 0.149\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.019 | top1-e-train: 0.009, top5-e-train: 0.004 | top1-e-test: 0.385, top5-e-test: 0.148\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.020 | top1-e-train: 0.004, top5-e-train: 0.001 | top1-e-test: 0.381, top5-e-test: 0.144\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.018 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.382, top5-e-test: 0.145\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.018 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.384, top5-e-test: 0.146\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.006, top5-e-train: 0.003 | top1-e-test: 0.384, top5-e-test: 0.146\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.382, top5-e-test: 0.146\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.008, top5-e-train: 0.004 | top1-e-test: 0.386, top5-e-test: 0.148\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.145\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.146\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.006, top5-e-train: 0.003 | top1-e-test: 0.384, top5-e-test: 0.149\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.007, top5-e-train: 0.004 | top1-e-test: 0.383, top5-e-test: 0.147\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.004, top5-e-train: 0.002 | top1-e-test: 0.382, top5-e-test: 0.146\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.145\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.006, top5-e-train: 0.003 | top1-e-test: 0.384, top5-e-test: 0.148\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.006, top5-e-train: 0.003 | top1-e-test: 0.385, top5-e-test: 0.147\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.010, top5-e-train: 0.005 | top1-e-test: 0.386, top5-e-test: 0.149\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.006, top5-e-train: 0.002 | top1-e-test: 0.385, top5-e-test: 0.146\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.007, top5-e-train: 0.004 | top1-e-test: 0.385, top5-e-test: 0.148\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.146\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.382, top5-e-test: 0.146\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.006, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.147\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.146\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.004, top5-e-train: 0.002 | top1-e-test: 0.382, top5-e-test: 0.144\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.009, top5-e-train: 0.005 | top1-e-test: 0.385, top5-e-test: 0.149\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.008, top5-e-train: 0.004 | top1-e-test: 0.383, top5-e-test: 0.148\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.146\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.146\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.006, top5-e-train: 0.003 | top1-e-test: 0.383, top5-e-test: 0.147\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.008, top5-e-train: 0.004 | top1-e-test: 0.384, top5-e-test: 0.147\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.015 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.385, top5-e-test: 0.146\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.003, top5-e-train: 0.001 | top1-e-test: 0.383, top5-e-test: 0.146\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.015 | top1-e-train: 0.006, top5-e-train: 0.003 | top1-e-test: 0.384, top5-e-test: 0.147\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.015 | top1-e-train: 0.004, top5-e-train: 0.002 | top1-e-test: 0.381, top5-e-test: 0.144\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.015 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.145\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.147\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.005, top5-e-train: 0.002 | top1-e-test: 0.383, top5-e-test: 0.146\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.003, top5-e-train: 0.001 | top1-e-test: 0.380, top5-e-test: 0.146\n",
            "--------- Finish Training --------\n",
            "Top1E:  0.379700005054\n",
            "Top5E:  0.143800020218\n",
            "\n",
            "\n",
            "e1_train:  [0.8982000350952148, 0.7976599931716919, 0.7249400019645691, 0.6630600094795227, 0.6193599700927734, 0.583299994468689, 0.5478800535202026, 0.5174599885940552, 0.4711199998855591, 0.44516003131866455, 0.4333000183105469, 0.412339985370636, 0.37248003482818604, 0.37092000246047974, 0.3396199941635132, 0.31992000341415405, 0.31150001287460327, 0.27632004022598267, 0.24976003170013428, 0.24972003698349, 0.24726003408432007, 0.22554004192352295, 0.21886003017425537, 0.22317999601364136, 0.16260004043579102, 0.1417199969291687, 0.12892001867294312, 0.11358004808425903, 0.11564004421234131, 0.04304003715515137, 0.03633999824523926, 0.028700053691864014, 0.025420010089874268, 0.021520018577575684, 0.02222001552581787, 0.01826000213623047, 0.014320015907287598, 0.01726001501083374, 0.017040014266967773, 0.011640012264251709, 0.012980043888092041, 0.013060033321380615, 0.01446002721786499, 0.009600043296813965, 0.012000024318695068, 0.013400018215179443, 0.01064002513885498, 0.010760009288787842, 0.009200036525726318, 0.008740007877349854, 0.007060050964355469, 0.008700013160705566, 0.0064400434494018555, 0.00736004114151001, 0.007019996643066406, 0.0072800517082214355, 0.006620049476623535, 0.010360002517700195, 0.007860004901885986, 0.009020030498504639, 0.006720006465911865, 0.005720019340515137, 0.005840003490447998, 0.0067999958992004395, 0.008800029754638672, 0.0040400028228759766, 0.004860043525695801, 0.005380034446716309, 0.006020009517669678, 0.005060017108917236, 0.007780015468597412, 0.005240023136138916, 0.0051400065422058105, 0.006420016288757324, 0.00718003511428833, 0.0038200020790100098, 0.00456005334854126, 0.005860030651092529, 0.006260037422180176, 0.009580016136169434, 0.005520045757293701, 0.007260024547576904, 0.004620015621185303, 0.004920005798339844, 0.005600035190582275, 0.004760026931762695, 0.003560006618499756, 0.008720040321350098, 0.007740020751953125, 0.005460023880004883, 0.005180001258850098, 0.006300032138824463, 0.007980048656463623, 0.005060017108917236, 0.0034400224685668945, 0.006060004234313965, 0.0042999982833862305, 0.005200028419494629, 0.004519999027252197, 0.00532001256942749, 0.003380000591278076]\n",
            "e5_train:  [0.6663399934768677, 0.5013200044631958, 0.40570002794265747, 0.3354400396347046, 0.28800004720687866, 0.2540000081062317, 0.22510004043579102, 0.20144003629684448, 0.16884005069732666, 0.14774000644683838, 0.13594001531600952, 0.12389999628067017, 0.10448002815246582, 0.09894001483917236, 0.0867200493812561, 0.07688003778457642, 0.06828004121780396, 0.05694001913070679, 0.046360015869140625, 0.044700026512145996, 0.04243999719619751, 0.03532004356384277, 0.02986001968383789, 0.0343400239944458, 0.01708000898361206, 0.011620044708251953, 0.009479999542236328, 0.00886005163192749, 0.009000003337860107, 0.002480030059814453, 0.003760039806365967, 0.002400040626525879, 0.002499997615814209, 0.0013800263404846191, 0.0025200247764587402, 0.0014600157737731934, 0.000800013542175293, 0.002160012722015381, 0.004760026931762695, 0.001980006694793701, 0.0029000043869018555, 0.0031400322914123535, 0.004460036754608154, 0.0018200278282165527, 0.004140019416809082, 0.0050400495529174805, 0.0034800171852111816, 0.003859996795654297, 0.0030600428581237793, 0.003080010414123535, 0.002140045166015625, 0.0028400421142578125, 0.0022200345993041992, 0.0023400187492370605, 0.0023000240325927734, 0.0023200511932373047, 0.0025800466537475586, 0.004440009593963623, 0.003560006618499756, 0.004160046577453613, 0.0028800368309020996, 0.0020200014114379883, 0.002160012722015381, 0.0029000043869018555, 0.0042999982833862305, 0.001300036907196045, 0.0017400383949279785, 0.002160012722015381, 0.0026400089263916016, 0.0020000338554382324, 0.0039000511169433594, 0.002160012722015381, 0.0021200180053710938, 0.0031800270080566406, 0.0035400390625, 0.001600027084350586, 0.001640021800994873, 0.0027199983596801758, 0.002780020236968994, 0.004940032958984375, 0.0024200081825256348, 0.0035400390625, 0.0020000338554382324, 0.0020000338554382324, 0.002480030059814453, 0.001940011978149414, 0.0015400052070617676, 0.004680037498474121, 0.003859996795654297, 0.0024200081825256348, 0.0023400187492370605, 0.0029000043869018555, 0.003920018672943115, 0.0020400285720825195, 0.0014800429344177246, 0.002960026264190674, 0.0017400383949279785, 0.0023400187492370605, 0.0020200014114379883, 0.0023200511932373047, 0.0012400150299072266]\n",
            "\n",
            "\n",
            "e1_test:  [0.897599995136261, 0.7797999978065491, 0.7136000394821167, 0.6563999652862549, 0.6260000467300415, 0.5902000069618225, 0.5746999979019165, 0.5493000149726868, 0.5212000012397766, 0.49790000915527344, 0.49779999256134033, 0.4937000274658203, 0.47450000047683716, 0.4747999906539917, 0.4607999920845032, 0.4521999955177307, 0.45100003480911255, 0.44179999828338623, 0.43860000371932983, 0.44370001554489136, 0.4413999915122986, 0.4417000412940979, 0.4366999864578247, 0.45350003242492676, 0.4305000305175781, 0.4269999861717224, 0.4271000027656555, 0.4244999885559082, 0.43300002813339233, 0.3944000005722046, 0.3962000012397766, 0.39010000228881836, 0.3912000060081482, 0.3906000256538391, 0.3910999894142151, 0.3888000249862671, 0.39100003242492676, 0.3888000249862671, 0.39259999990463257, 0.3896999955177307, 0.3896999955177307, 0.3913000226020813, 0.3927000164985657, 0.38780003786087036, 0.3888000249862671, 0.3938000202178955, 0.3899000287055969, 0.3903999924659729, 0.3899000287055969, 0.3921000361442566, 0.3871000409126282, 0.3895000219345093, 0.38850003480911255, 0.3871000409126282, 0.3866000175476074, 0.3862000107765198, 0.38840001821517944, 0.3907000422477722, 0.3899000287055969, 0.38700002431869507, 0.38530004024505615, 0.38440001010894775, 0.3831999897956848, 0.3849000334739685, 0.3849000334739685, 0.38050001859664917, 0.3817000389099121, 0.3841000199317932, 0.3842000365257263, 0.38179999589920044, 0.38580000400543213, 0.3833000063896179, 0.38270002603530884, 0.38440001010894775, 0.383400022983551, 0.3815000057220459, 0.38280004262924194, 0.3842000365257263, 0.38530004024505615, 0.385699987411499, 0.38450002670288086, 0.3853999972343445, 0.38260000944137573, 0.381600022315979, 0.3830000162124634, 0.3830000162124634, 0.38179999589920044, 0.3848000168800354, 0.383400022983551, 0.3828999996185303, 0.3831000328063965, 0.38270002603530884, 0.38370001316070557, 0.38460004329681396, 0.38280004262924194, 0.3841000199317932, 0.3810000419616699, 0.38270002603530884, 0.38260000944137573, 0.38260000944137573, 0.3797000050544739]\n",
            "e5_test:  [0.6607000231742859, 0.4927000403404236, 0.39250004291534424, 0.3372000455856323, 0.3043000102043152, 0.27310001850128174, 0.2517000436782837, 0.23930001258850098, 0.22190004587173462, 0.1982000470161438, 0.19900000095367432, 0.19499999284744263, 0.18070000410079956, 0.18320000171661377, 0.17480003833770752, 0.17640000581741333, 0.16740000247955322, 0.16380000114440918, 0.17000001668930054, 0.16949999332427979, 0.1728000044822693, 0.17070001363754272, 0.17059999704360962, 0.18130004405975342, 0.16540002822875977, 0.16530001163482666, 0.16170001029968262, 0.1607000231742859, 0.1633000373840332, 0.14670002460479736, 0.14740002155303955, 0.14560002088546753, 0.14480000734329224, 0.14640003442764282, 0.1447000503540039, 0.14500004053115845, 0.14590001106262207, 0.1462000012397766, 0.15119999647140503, 0.1454000473022461, 0.14890003204345703, 0.1470000147819519, 0.1509000062942505, 0.14560002088546753, 0.14640003442764282, 0.1486000418663025, 0.1462000012397766, 0.14670002460479736, 0.14399999380111694, 0.14720004796981812, 0.145300030708313, 0.14650005102157593, 0.14570003747940063, 0.14630001783370972, 0.14640003442764282, 0.1477000117301941, 0.1478000283241272, 0.147100031375885, 0.1511000394821167, 0.14930003881454468, 0.14850002527236938, 0.14750003814697266, 0.14640003442764282, 0.14880001544952393, 0.14820003509521484, 0.14410001039505005, 0.1445000171661377, 0.14579999446868896, 0.14640003442764282, 0.14560002088546753, 0.1479000449180603, 0.1446000337600708, 0.14560002088546753, 0.14890003204345703, 0.147100031375885, 0.14579999446868896, 0.145300030708313, 0.14750003814697266, 0.14740002155303955, 0.14869999885559082, 0.14560002088546753, 0.1479000449180603, 0.14590001106262207, 0.14560002088546753, 0.14650005102157593, 0.1462000012397766, 0.14430004358291626, 0.14900004863739014, 0.1477000117301941, 0.1462000012397766, 0.14630001783370972, 0.14740002155303955, 0.14740002155303955, 0.14550000429153442, 0.14640003442764282, 0.14680004119873047, 0.1438000202178955, 0.145300030708313, 0.1470000147819519, 0.14590001106262207, 0.14600002765655518]\n",
            "\n",
            "\n",
            "TIME:  6903.79050708\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n",
            "Namespace(arch='cbam_resnet34', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 3.712 | top1-e-train: 0.806, top5-e-train: 0.514 | top1-e-test: 0.788, top5-e-test: 0.495\n",
            "[Epoch   1], lr: 0.10000, Loss: 2.972 | top1-e-train: 0.697, top5-e-train: 0.376 | top1-e-test: 0.691, top5-e-test: 0.369\n",
            "[Epoch   2], lr: 0.10000, Loss: 2.560 | top1-e-train: 0.649, top5-e-train: 0.320 | top1-e-test: 0.645, top5-e-test: 0.322\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.283 | top1-e-train: 0.622, top5-e-train: 0.304 | top1-e-test: 0.620, top5-e-test: 0.305\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.076 | top1-e-train: 0.556, top5-e-train: 0.234 | top1-e-test: 0.576, top5-e-test: 0.262\n",
            "[Epoch   5], lr: 0.10000, Loss: 1.899 | top1-e-train: 0.508, top5-e-train: 0.199 | top1-e-test: 0.535, top5-e-test: 0.240\n",
            "[Epoch   6], lr: 0.10000, Loss: 1.752 | top1-e-train: 0.481, top5-e-train: 0.174 | top1-e-test: 0.527, top5-e-test: 0.220\n",
            "[Epoch   7], lr: 0.10000, Loss: 1.628 | top1-e-train: 0.458, top5-e-train: 0.159 | top1-e-test: 0.516, top5-e-test: 0.219\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.525 | top1-e-train: 0.394, top5-e-train: 0.118 | top1-e-test: 0.472, top5-e-test: 0.178\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.416 | top1-e-train: 0.361, top5-e-train: 0.097 | top1-e-test: 0.459, top5-e-test: 0.169\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.314 | top1-e-train: 0.368, top5-e-train: 0.097 | top1-e-test: 0.472, top5-e-test: 0.180\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.228 | top1-e-train: 0.354, top5-e-train: 0.097 | top1-e-test: 0.469, top5-e-test: 0.186\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.143 | top1-e-train: 0.325, top5-e-train: 0.078 | top1-e-test: 0.453, top5-e-test: 0.170\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.068 | top1-e-train: 0.279, top5-e-train: 0.056 | top1-e-test: 0.435, top5-e-test: 0.158\n",
            "[Epoch  14], lr: 0.10000, Loss: 0.981 | top1-e-train: 0.295, top5-e-train: 0.058 | top1-e-test: 0.449, top5-e-test: 0.170\n",
            "[Epoch  15], lr: 0.10000, Loss: 0.916 | top1-e-train: 0.257, top5-e-train: 0.046 | top1-e-test: 0.432, top5-e-test: 0.160\n",
            "[Epoch  16], lr: 0.10000, Loss: 0.833 | top1-e-train: 0.226, top5-e-train: 0.036 | top1-e-test: 0.434, top5-e-test: 0.159\n",
            "[Epoch  17], lr: 0.10000, Loss: 0.760 | top1-e-train: 0.187, top5-e-train: 0.023 | top1-e-test: 0.417, top5-e-test: 0.150\n",
            "[Epoch  18], lr: 0.10000, Loss: 0.694 | top1-e-train: 0.189, top5-e-train: 0.024 | top1-e-test: 0.424, top5-e-test: 0.154\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.635 | top1-e-train: 0.166, top5-e-train: 0.018 | top1-e-test: 0.420, top5-e-test: 0.156\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.572 | top1-e-train: 0.167, top5-e-train: 0.018 | top1-e-test: 0.419, top5-e-test: 0.158\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.508 | top1-e-train: 0.147, top5-e-train: 0.013 | top1-e-test: 0.425, top5-e-test: 0.159\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.458 | top1-e-train: 0.127, top5-e-train: 0.009 | top1-e-test: 0.428, top5-e-test: 0.158\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.410 | top1-e-train: 0.112, top5-e-train: 0.008 | top1-e-test: 0.422, top5-e-test: 0.156\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.376 | top1-e-train: 0.107, top5-e-train: 0.007 | top1-e-test: 0.415, top5-e-test: 0.159\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.330 | top1-e-train: 0.084, top5-e-train: 0.004 | top1-e-test: 0.415, top5-e-test: 0.153\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.290 | top1-e-train: 0.080, top5-e-train: 0.004 | top1-e-test: 0.419, top5-e-test: 0.159\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.263 | top1-e-train: 0.072, top5-e-train: 0.003 | top1-e-test: 0.411, top5-e-test: 0.158\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.244 | top1-e-train: 0.063, top5-e-train: 0.002 | top1-e-test: 0.410, top5-e-test: 0.157\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.124 | top1-e-train: 0.019, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.136\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.079 | top1-e-train: 0.013, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.134\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.066 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.133\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.058 | top1-e-train: 0.010, top5-e-train: 0.000 | top1-e-test: 0.370, top5-e-test: 0.132\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.049 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.370, top5-e-test: 0.132\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.046 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.370, top5-e-test: 0.131\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.040 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.367, top5-e-test: 0.132\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.367, top5-e-test: 0.133\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.035 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.369, top5-e-test: 0.133\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.031 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.132\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.030 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.367, top5-e-test: 0.133\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.028 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.368, top5-e-test: 0.132\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.027 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.367, top5-e-test: 0.134\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.025 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.367, top5-e-test: 0.134\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.023 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.132\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.368, top5-e-test: 0.133\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.368, top5-e-test: 0.135\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.020 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.368, top5-e-test: 0.133\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.020 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.133\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.019 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.368, top5-e-test: 0.134\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.018 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.132\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.018 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.133\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.017 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.134\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.132\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.132\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.016 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.131\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.132\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.133\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.135\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.133\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.132\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.133\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.132\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.132\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.134\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.133\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.133\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.133\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.366, top5-e-test: 0.133\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.132\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.133\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.132\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.133\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.133\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.132\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.134\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.132\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.133\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.132\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.133\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.132\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.132\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.133\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.133\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.132\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.133\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.134\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.133\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.132\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.131\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.133\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.133\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.132\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.011 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.133\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.133\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.362, top5-e-test: 0.133\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.132\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.134\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.363, top5-e-test: 0.132\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.132\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.364, top5-e-test: 0.133\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.010 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.365, top5-e-test: 0.134\n",
            "--------- Finish Training --------\n",
            "Top1E:  0.362200021744\n",
            "Top5E:  0.130800008774\n",
            "\n",
            "\n",
            "e1_train:  [0.8056399822235107, 0.697100043296814, 0.649399995803833, 0.6222200393676758, 0.5558000206947327, 0.507860004901886, 0.4807400107383728, 0.4583200216293335, 0.3941799998283386, 0.36080002784729004, 0.36774003505706787, 0.35412001609802246, 0.32464003562927246, 0.2793000340461731, 0.294979989528656, 0.2566600441932678, 0.22614002227783203, 0.18738001585006714, 0.18884003162384033, 0.16554003953933716, 0.16666001081466675, 0.14732003211975098, 0.1265600323677063, 0.11152005195617676, 0.10686004161834717, 0.08442002534866333, 0.08016002178192139, 0.07190001010894775, 0.06322002410888672, 0.018519997596740723, 0.01296001672744751, 0.011200010776519775, 0.009580016136169434, 0.0075400471687316895, 0.006940007209777832, 0.005879998207092285, 0.005460023880004883, 0.005160033702850342, 0.004880011081695557, 0.004360020160675049, 0.0037200450897216797, 0.0034000277519226074, 0.0033600330352783203, 0.003080010414123535, 0.002660036087036133, 0.00270003080368042, 0.002740025520324707, 0.0023400187492370605, 0.0026800036430358887, 0.001940011978149414, 0.0017200112342834473, 0.0024200081825256348, 0.0020400285720825195, 0.0016600489616394043, 0.0014600157737731934, 0.0015200376510620117, 0.0016600489616394043, 0.0017600059509277344, 0.0015400052070617676, 0.0013800263404846191, 0.0013599991798400879, 0.0016200542449951172, 0.0014600157737731934, 0.0011800527572631836, 0.0013599991798400879, 0.0010800361633300781, 0.0014000535011291504, 0.001300036907196045, 0.0013599991798400879, 0.0013599991798400879, 0.001300036907196045, 0.0013200044631958008, 0.0011600255966186523, 0.0010600090026855469, 0.001340031623840332, 0.0010200142860412598, 0.0008600354194641113, 0.0011800527572631836, 0.001000046730041504, 0.0010200142860412598, 0.0014000535011291504, 0.001000046730041504, 0.0008600354194641113, 0.001300036907196045, 0.001139998435974121, 0.0012000203132629395, 0.0009400248527526855, 0.0010600090026855469, 0.001340031623840332, 0.001000046730041504, 0.001040041446685791, 0.0010800361633300781, 0.0009800195693969727, 0.0010200142860412598, 0.0009400248527526855, 0.0012400150299072266, 0.0010200142860412598, 0.0012600421905517578, 0.0011200308799743652, 0.0009600520133972168, 0.0008400082588195801]\n",
            "e5_train:  [0.5143400430679321, 0.37643998861312866, 0.32006001472473145, 0.3044000267982483, 0.23440003395080566, 0.1992800235748291, 0.17358005046844482, 0.15896004438400269, 0.11796003580093384, 0.0972599983215332, 0.09744000434875488, 0.09728002548217773, 0.0781400203704834, 0.05612003803253174, 0.05836004018783569, 0.046080052852630615, 0.03586000204086304, 0.023460030555725098, 0.02376002073287964, 0.017580032348632812, 0.018280029296875, 0.012620031833648682, 0.009420037269592285, 0.007500052452087402, 0.0067999958992004395, 0.004280030727386475, 0.0036600232124328613, 0.0031800270080566406, 0.002360045909881592, 0.0003000497817993164, 0.0001800060272216797, 0.00012004375457763672, 0.0001800060272216797, 2.002716064453125e-05, 8.004903793334961e-05, 2.002716064453125e-05, 6.002187728881836e-05, 2.002716064453125e-05, 2.002716064453125e-05, 0.0, 6.002187728881836e-05, 2.002716064453125e-05, 4.00543212890625e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.002716064453125e-05, 0.0, 0.0, 0.0, 0.0, 2.002716064453125e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.002716064453125e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.002716064453125e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "\n",
            "e1_test:  [0.7876999974250793, 0.6914000511169434, 0.6450999975204468, 0.6200000047683716, 0.5763000249862671, 0.534500002861023, 0.5271999835968018, 0.515500009059906, 0.47220003604888916, 0.4585999846458435, 0.471500039100647, 0.46890002489089966, 0.4532000422477722, 0.4345000386238098, 0.4492000341415405, 0.43150001764297485, 0.4343000054359436, 0.4174000024795532, 0.4244999885559082, 0.4204000234603882, 0.4187999963760376, 0.42489999532699585, 0.42760002613067627, 0.42239999771118164, 0.41519999504089355, 0.414900004863739, 0.41850000619888306, 0.41110002994537354, 0.4104999899864197, 0.38020002841949463, 0.3733000159263611, 0.37150001525878906, 0.37040001153945923, 0.3698999881744385, 0.36980003118515015, 0.36730003356933594, 0.36720001697540283, 0.36900001764297485, 0.366100013256073, 0.3666999936103821, 0.3677000403404236, 0.3671000003814697, 0.36720001697540283, 0.36570000648498535, 0.367900013923645, 0.3676000237464905, 0.3680000305175781, 0.3659999966621399, 0.3676000237464905, 0.36629998683929443, 0.3647000193595886, 0.3655000329017639, 0.3644000291824341, 0.3655000329017639, 0.36480003595352173, 0.36510002613067627, 0.36480003595352173, 0.3646000027656555, 0.36260002851486206, 0.3652000427246094, 0.36340004205703735, 0.3644000291824341, 0.3622000217437744, 0.36419999599456787, 0.36250001192092896, 0.36390000581741333, 0.3637999892234802, 0.36629998683929443, 0.36330002546310425, 0.3630000352859497, 0.3652000427246094, 0.3654000163078308, 0.364300012588501, 0.3645000457763672, 0.36419999599456787, 0.36400002241134644, 0.3654000163078308, 0.3647000193595886, 0.3644000291824341, 0.36480003595352173, 0.36340004205703735, 0.36320000886917114, 0.3647000193595886, 0.36489999294281006, 0.36480003595352173, 0.36400002241134644, 0.36489999294281006, 0.36320000886917114, 0.3630000352859497, 0.3636000156402588, 0.3644000291824341, 0.36260002851486206, 0.3634999990463257, 0.3646000027656555, 0.3622000217437744, 0.3646000027656555, 0.3652000427246094, 0.36320000886917114, 0.364300012588501, 0.3636000156402588, 0.3645000457763672]\n",
            "e5_test:  [0.49459999799728394, 0.3693000078201294, 0.3215000033378601, 0.30480003356933594, 0.2621000409126282, 0.24020004272460938, 0.22030001878738403, 0.21900004148483276, 0.17800003290176392, 0.16870003938674927, 0.17980003356933594, 0.1860000491142273, 0.16990000009536743, 0.15830004215240479, 0.17020004987716675, 0.16040003299713135, 0.15880000591278076, 0.14980000257492065, 0.1543000340461731, 0.15619999170303345, 0.1575000286102295, 0.15880000591278076, 0.15830004215240479, 0.15619999170303345, 0.15870004892349243, 0.15250003337860107, 0.15860003232955933, 0.1576000452041626, 0.15650004148483276, 0.1357000470161438, 0.1340000033378601, 0.13260000944137573, 0.131600022315979, 0.131600022315979, 0.1308000087738037, 0.13179999589920044, 0.13300001621246338, 0.13330000638961792, 0.13220000267028809, 0.13270002603530884, 0.1317000389099121, 0.13420003652572632, 0.13420003652572632, 0.13210004568099976, 0.13260000944137573, 0.1349000334739685, 0.13289999961853027, 0.13340002298355103, 0.13380002975463867, 0.13200002908706665, 0.13280004262924194, 0.13390004634857178, 0.13249999284744263, 0.13210004568099976, 0.1308000087738037, 0.13210004568099976, 0.13300001621246338, 0.13450002670288086, 0.13300001621246338, 0.1323000192642212, 0.13300001621246338, 0.131600022315979, 0.1317000389099121, 0.13359999656677246, 0.13260000944137573, 0.13330000638961792, 0.13300001621246338, 0.13270002603530884, 0.1323000192642212, 0.13300001621246338, 0.13179999589920044, 0.13260000944137573, 0.13289999961853027, 0.13190001249313354, 0.13350003957748413, 0.13210004568099976, 0.13280004262924194, 0.13210004568099976, 0.13260000944137573, 0.13249999284744263, 0.1323000192642212, 0.13340002298355103, 0.1332000494003296, 0.13200002908706665, 0.13340002298355103, 0.13370001316070557, 0.13300001621246338, 0.13190001249313354, 0.13120001554489136, 0.13270002603530884, 0.13289999961853027, 0.1323000192642212, 0.13310003280639648, 0.13260000944137573, 0.13260000944137573, 0.13220000267028809, 0.13370001316070557, 0.13220000267028809, 0.1317000389099121, 0.13270002603530884, 0.13380002975463867]\n",
            "\n",
            "\n",
            "TIME:  8286.88142014\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}