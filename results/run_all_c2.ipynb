{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_all_c2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenvietan/DL_Attention_PA1_ee898/blob/master/run_all_c2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dnjcSx1pwu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4219
        },
        "outputId": "3e032f89-c3c0-4350-81f0-1ada37fe1318"
      },
      "source": [
        "!bash run_all_c2.sh\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(arch='cbam_resnet50_c', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Model:  cbam_resnet50_c\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 4.626 | top1-e-train: 0.951, top5-e-train: 0.811 | top1-e-test: 0.952, top5-e-test: 0.808\n",
            "[Epoch   1], lr: 0.10000, Loss: 3.900 | top1-e-train: 0.854, top5-e-train: 0.595 | top1-e-test: 0.856, top5-e-test: 0.591\n",
            "[Epoch   2], lr: 0.10000, Loss: 3.370 | top1-e-train: 0.778, top5-e-train: 0.477 | top1-e-test: 0.771, top5-e-test: 0.468\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.952 | top1-e-train: 0.707, top5-e-train: 0.383 | top1-e-test: 0.708, top5-e-test: 0.385\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.621 | top1-e-train: 0.651, top5-e-train: 0.320 | top1-e-test: 0.658, top5-e-test: 0.330\n",
            "[Epoch   5], lr: 0.10000, Loss: 2.362 | top1-e-train: 0.614, top5-e-train: 0.292 | top1-e-test: 0.625, top5-e-test: 0.311\n",
            "[Epoch   6], lr: 0.10000, Loss: 2.157 | top1-e-train: 0.548, top5-e-train: 0.224 | top1-e-test: 0.576, top5-e-test: 0.255\n",
            "[Epoch   7], lr: 0.10000, Loss: 2.055 | top1-e-train: 0.510, top5-e-train: 0.198 | top1-e-test: 0.552, top5-e-test: 0.242\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.861 | top1-e-train: 0.484, top5-e-train: 0.175 | top1-e-test: 0.530, top5-e-test: 0.223\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.738 | top1-e-train: 0.462, top5-e-train: 0.157 | top1-e-test: 0.516, top5-e-test: 0.213\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.630 | top1-e-train: 0.449, top5-e-train: 0.150 | top1-e-test: 0.512, top5-e-test: 0.205\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.573 | top1-e-train: 0.437, top5-e-train: 0.145 | top1-e-test: 0.519, top5-e-test: 0.219\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.448 | top1-e-train: 0.370, top5-e-train: 0.102 | top1-e-test: 0.463, top5-e-test: 0.181\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.624 | top1-e-train: 0.427, top5-e-train: 0.135 | top1-e-test: 0.502, top5-e-test: 0.202\n",
            "[Epoch  14], lr: 0.10000, Loss: 1.479 | top1-e-train: 0.368, top5-e-train: 0.101 | top1-e-test: 0.475, top5-e-test: 0.184\n",
            "[Epoch  15], lr: 0.10000, Loss: 1.294 | top1-e-train: 0.328, top5-e-train: 0.080 | top1-e-test: 0.448, top5-e-test: 0.169\n",
            "[Epoch  16], lr: 0.10000, Loss: 1.180 | top1-e-train: 0.308, top5-e-train: 0.070 | top1-e-test: 0.454, top5-e-test: 0.171\n",
            "[Epoch  17], lr: 0.10000, Loss: 1.090 | top1-e-train: 0.319, top5-e-train: 0.084 | top1-e-test: 0.452, top5-e-test: 0.173\n",
            "[Epoch  18], lr: 0.10000, Loss: 1.015 | top1-e-train: 0.255, top5-e-train: 0.050 | top1-e-test: 0.442, top5-e-test: 0.168\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.929 | top1-e-train: 0.232, top5-e-train: 0.040 | top1-e-test: 0.444, top5-e-test: 0.162\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.843 | top1-e-train: 0.227, top5-e-train: 0.035 | top1-e-test: 0.445, top5-e-test: 0.166\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.776 | top1-e-train: 0.196, top5-e-train: 0.027 | top1-e-test: 0.436, top5-e-test: 0.168\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.701 | top1-e-train: 0.194, top5-e-train: 0.026 | top1-e-test: 0.442, top5-e-test: 0.165\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.654 | top1-e-train: 0.176, top5-e-train: 0.020 | top1-e-test: 0.434, top5-e-test: 0.160\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.587 | top1-e-train: 0.156, top5-e-train: 0.016 | top1-e-test: 0.428, top5-e-test: 0.157\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.530 | top1-e-train: 0.133, top5-e-train: 0.011 | top1-e-test: 0.430, top5-e-test: 0.162\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.467 | top1-e-train: 0.125, top5-e-train: 0.009 | top1-e-test: 0.422, top5-e-test: 0.159\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.432 | top1-e-train: 0.126, top5-e-train: 0.011 | top1-e-test: 0.432, top5-e-test: 0.165\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.391 | top1-e-train: 0.124, top5-e-train: 0.010 | top1-e-test: 0.433, top5-e-test: 0.170\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.201 | top1-e-train: 0.036, top5-e-train: 0.001 | top1-e-test: 0.386, top5-e-test: 0.140\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.132 | top1-e-train: 0.026, top5-e-train: 0.001 | top1-e-test: 0.379, top5-e-test: 0.138\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.109 | top1-e-train: 0.020, top5-e-train: 0.001 | top1-e-test: 0.379, top5-e-test: 0.137\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.090 | top1-e-train: 0.019, top5-e-train: 0.001 | top1-e-test: 0.375, top5-e-test: 0.136\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.081 | top1-e-train: 0.017, top5-e-train: 0.001 | top1-e-test: 0.377, top5-e-test: 0.136\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.075 | top1-e-train: 0.014, top5-e-train: 0.001 | top1-e-test: 0.377, top5-e-test: 0.134\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.066 | top1-e-train: 0.013, top5-e-train: 0.001 | top1-e-test: 0.376, top5-e-test: 0.138\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.062 | top1-e-train: 0.012, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.134\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.056 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.138\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.054 | top1-e-train: 0.009, top5-e-train: 0.001 | top1-e-test: 0.376, top5-e-test: 0.137\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.049 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.141\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.045 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.374, top5-e-test: 0.137\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.042 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.374, top5-e-test: 0.140\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.042 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.375, top5-e-test: 0.138\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.374, top5-e-test: 0.137\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.036 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.375, top5-e-test: 0.137\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.035 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.137\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.033 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.375, top5-e-test: 0.138\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.031 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.137\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.029 | top1-e-train: 0.006, top5-e-train: 0.001 | top1-e-test: 0.376, top5-e-test: 0.139\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.028 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.139\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.028 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.375, top5-e-test: 0.138\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.027 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.137\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.025 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.139\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.025 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.139\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.025 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.138\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.023 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.140\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.375, top5-e-test: 0.138\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.376, top5-e-test: 0.138\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.020 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.137\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.018 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.138\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.018 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.138\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.139\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.017 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.139\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.138\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.137\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.139\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.139\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.138\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.139\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.137\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.139\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.138\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.139\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.370, top5-e-test: 0.138\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.140\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.375, top5-e-test: 0.138\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.138\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.139\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.370, top5-e-test: 0.138\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.137\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.137\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.138\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.139\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.137\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.139\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.139\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.138\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.373, top5-e-test: 0.139\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.014 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.372, top5-e-test: 0.138\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.371, top5-e-test: 0.139\n",
            "--------- Finish Training --------\n",
            "Model:  cbam_resnet50_c\n",
            "Top1E:  0.370100021362\n",
            "Top5E:  0.134200036526\n",
            "\n",
            "\n",
            "e1_train:  [0.9513599872589111, 0.8541600108146667, 0.7777199745178223, 0.7067999839782715, 0.6511600017547607, 0.6136599779129028, 0.5480599999427795, 0.5095200538635254, 0.4843199849128723, 0.4618000388145447, 0.44863998889923096, 0.4365200400352478, 0.3702000379562378, 0.4273800253868103, 0.36809998750686646, 0.32784003019332886, 0.30840003490448, 0.31880003213882446, 0.25481998920440674, 0.2323000431060791, 0.22684001922607422, 0.19554001092910767, 0.19388002157211304, 0.17599999904632568, 0.1560400128364563, 0.13332003355026245, 0.12490004301071167, 0.12558001279830933, 0.1241600513458252, 0.036100029945373535, 0.0261000394821167, 0.020220041275024414, 0.018959999084472656, 0.017000019550323486, 0.013779997825622559, 0.013040006160736084, 0.01166003942489624, 0.010600030422210693, 0.009420037269592285, 0.007960021495819092, 0.007560014724731445, 0.007239997386932373, 0.006460011005401611, 0.0062400102615356445, 0.00634002685546875, 0.005480051040649414, 0.005160033702850342, 0.004860043525695801, 0.005860030651092529, 0.0045400261878967285, 0.0048400163650512695, 0.0048400163650512695, 0.0042999982833862305, 0.0037200450897216797, 0.0035400390625, 0.0031599998474121094, 0.0035400390625, 0.002780020236968994, 0.002140045166015625, 0.0022600293159484863, 0.0023200511932373047, 0.002360045909881592, 0.002240002155303955, 0.0020800232887268066, 0.0025600194931030273, 0.002460002899169922, 0.002160012722015381, 0.0020599961280822754, 0.0020599961280822754, 0.001980006694793701, 0.0017200112342834473, 0.0020000338554382324, 0.001900017261505127, 0.0018600225448608398, 0.0020200014114379883, 0.0018600225448608398, 0.0015799999237060547, 0.0018000006675720215, 0.0014800429344177246, 0.0018600225448608398, 0.001600027084350586, 0.001840054988861084, 0.0016800165176391602, 0.0015400052070617676, 0.0015200376510620117, 0.0017000436782836914, 0.0014000535011291504, 0.0014200210571289062, 0.0014800429344177246, 0.0014800429344177246, 0.0012800097465515137, 0.001940011978149414, 0.0014000535011291504, 0.001840054988861084, 0.001640021800994873, 0.001840054988861084, 0.001900017261505127, 0.0016800165176391602, 0.001880049705505371, 0.0012600421905517578, 0.0014800429344177246]\n",
            "e5_train:  [0.8112000226974487, 0.5945800542831421, 0.47703999280929565, 0.38328003883361816, 0.3199000358581543, 0.29236000776290894, 0.2238200306892395, 0.19822001457214355, 0.1746000051498413, 0.15654003620147705, 0.15048003196716309, 0.14496004581451416, 0.10234004259109497, 0.13528001308441162, 0.10133999586105347, 0.08040004968643188, 0.07012003660202026, 0.0840800404548645, 0.04992002248764038, 0.04000002145767212, 0.035420000553131104, 0.026500046253204346, 0.025660037994384766, 0.019820034503936768, 0.015740036964416504, 0.010880053043365479, 0.009080052375793457, 0.010680019855499268, 0.009640038013458252, 0.001300036907196045, 0.001100003719329834, 0.0005600452423095703, 0.0009000301361083984, 0.0011200308799743652, 0.0005200505256652832, 0.0006800293922424316, 0.0003600120544433594, 0.0002599954605102539, 0.000500023365020752, 0.00016003847122192383, 0.00028002262115478516, 0.0002200007438659668, 0.00010001659393310547, 6.002187728881836e-05, 0.00014001131057739258, 0.00032001733779907227, 0.0001800060272216797, 0.00014001131057739258, 0.0006000399589538574, 0.0003000497817993164, 0.00028002262115478516, 0.00032001733779907227, 0.00028002262115478516, 0.00020003318786621094, 8.004903793334961e-05, 0.00012004375457763672, 6.002187728881836e-05, 4.00543212890625e-05, 4.00543212890625e-05, 6.002187728881836e-05, 8.004903793334961e-05, 4.00543212890625e-05, 4.00543212890625e-05, 4.00543212890625e-05, 6.002187728881836e-05, 6.002187728881836e-05, 6.002187728881836e-05, 6.002187728881836e-05, 8.004903793334961e-05, 4.00543212890625e-05, 4.00543212890625e-05, 2.002716064453125e-05, 4.00543212890625e-05, 0.0, 4.00543212890625e-05, 2.002716064453125e-05, 2.002716064453125e-05, 8.004903793334961e-05, 6.002187728881836e-05, 4.00543212890625e-05, 2.002716064453125e-05, 0.0, 2.002716064453125e-05, 0.0, 2.002716064453125e-05, 2.002716064453125e-05, 2.002716064453125e-05, 2.002716064453125e-05, 0.0, 0.0, 0.0, 6.002187728881836e-05, 6.002187728881836e-05, 0.0, 2.002716064453125e-05, 4.00543212890625e-05, 6.002187728881836e-05, 2.002716064453125e-05, 0.0, 0.0, 0.0]\n",
            "\n",
            "\n",
            "e1_test:  [0.9516000151634216, 0.8557000160217285, 0.771399974822998, 0.7080000042915344, 0.6577000021934509, 0.625, 0.5760999917984009, 0.552299976348877, 0.5299999713897705, 0.5164999961853027, 0.5123000144958496, 0.5194000005722046, 0.4632999897003174, 0.501800000667572, 0.47540003061294556, 0.4480000138282776, 0.4538000226020813, 0.4524000287055969, 0.4422000050544739, 0.4438999891281128, 0.4448000192642212, 0.43639999628067017, 0.4416000247001648, 0.43389999866485596, 0.4277999997138977, 0.4296000003814697, 0.42239999771118164, 0.4318000078201294, 0.4325000047683716, 0.38600003719329834, 0.3790000081062317, 0.37880003452301025, 0.374500036239624, 0.3766000270843506, 0.3774000406265259, 0.3756999969482422, 0.3797000050544739, 0.37720000743865967, 0.37620002031326294, 0.3765000104904175, 0.3744000196456909, 0.3741000294685364, 0.37480002641677856, 0.37400001287460327, 0.37529999017715454, 0.3766000270843506, 0.37529999017715454, 0.3734999895095825, 0.37560003995895386, 0.3781999945640564, 0.3751000165939331, 0.3758000135421753, 0.3734000325202942, 0.37209999561309814, 0.3758000135421753, 0.37300002574920654, 0.37480002641677856, 0.3759000301361084, 0.3734999895095825, 0.372700035572052, 0.3716999888420105, 0.3711000084877014, 0.3719000220298767, 0.37240004539489746, 0.37209999561309814, 0.3712000250816345, 0.37279999256134033, 0.37240004539489746, 0.3716999888420105, 0.3712000250816345, 0.37139999866485596, 0.3716999888420105, 0.37240004539489746, 0.37230002880096436, 0.37090003490448, 0.37090003490448, 0.3733000159263611, 0.3720000386238098, 0.37040001153945923, 0.3709999918937683, 0.37490004301071167, 0.37090003490448, 0.37150001525878906, 0.3716999888420105, 0.3701000213623047, 0.37230002880096436, 0.3716999888420105, 0.3726000189781189, 0.37220001220703125, 0.37220001220703125, 0.37090003490448, 0.37160003185272217, 0.37060004472732544, 0.3718000054359436, 0.3720000386238098, 0.37279999256134033, 0.3713000416755676, 0.37300002574920654, 0.3719000220298767, 0.37230002880096436, 0.3712000250816345]\n",
            "e5_test:  [0.8077000379562378, 0.5913000106811523, 0.46799999475479126, 0.3848000168800354, 0.3296999931335449, 0.3109000325202942, 0.25460004806518555, 0.2419000267982483, 0.2226000428199768, 0.2128000259399414, 0.20490002632141113, 0.2193000316619873, 0.1811000108718872, 0.2021999955177307, 0.1844000220298767, 0.16870003938674927, 0.17090004682540894, 0.17340004444122314, 0.16760003566741943, 0.16150003671646118, 0.1656000018119812, 0.16820001602172852, 0.16530001163482666, 0.1600000262260437, 0.1565999984741211, 0.16150003671646118, 0.15850001573562622, 0.16470003128051758, 0.17020004987716675, 0.14000004529953003, 0.13760000467300415, 0.1371999979019165, 0.1356000304222107, 0.13590002059936523, 0.13440001010894775, 0.13760000467300415, 0.13420003652572632, 0.1380000114440918, 0.13680005073547363, 0.14070004224777222, 0.13700002431869507, 0.13950002193450928, 0.13830000162124634, 0.13710004091262817, 0.13740003108978271, 0.13740003108978271, 0.13780003786087036, 0.13650000095367432, 0.13940000534057617, 0.13870000839233398, 0.13750004768371582, 0.13690000772476196, 0.13930004835128784, 0.13920003175735474, 0.1380000114440918, 0.14000004529953003, 0.138200044631958, 0.13830000162124634, 0.1371999979019165, 0.13780003786087036, 0.1381000280380249, 0.13840001821517944, 0.1380000114440918, 0.138200044631958, 0.13850003480911255, 0.13910001516342163, 0.13780003786087036, 0.13740003108978271, 0.13899999856948853, 0.13899999856948853, 0.13750004768371582, 0.13850003480911255, 0.13710004091262817, 0.13780003786087036, 0.13899999856948853, 0.13760000467300415, 0.1389000415802002, 0.1380000114440918, 0.13840001821517944, 0.1396999955177307, 0.13780003786087036, 0.1381000280380249, 0.13860005140304565, 0.13750004768371582, 0.13830000162124634, 0.13760000467300415, 0.13830000162124634, 0.13740003108978271, 0.13750004768371582, 0.13710004091262817, 0.13780003786087036, 0.13850003480911255, 0.13650000095367432, 0.13760000467300415, 0.13850003480911255, 0.13870000839233398, 0.1381000280380249, 0.13860005140304565, 0.138200044631958, 0.1380000114440918, 0.13850003480911255]\n",
            "\n",
            "\n",
            "TIME:  13804.1168311\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n",
            "Namespace(arch='cbam_resnet34_c', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Model:  cbam_resnet34_c\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 3.824 | top1-e-train: 0.831, top5-e-train: 0.553 | top1-e-test: 0.823, top5-e-test: 0.544\n",
            "[Epoch   1], lr: 0.10000, Loss: 3.118 | top1-e-train: 0.737, top5-e-train: 0.417 | top1-e-test: 0.735, top5-e-test: 0.416\n",
            "[Epoch   2], lr: 0.10000, Loss: 2.795 | top1-e-train: 0.702, top5-e-train: 0.399 | top1-e-test: 0.683, top5-e-test: 0.380\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.519 | top1-e-train: 0.649, top5-e-train: 0.319 | top1-e-test: 0.653, top5-e-test: 0.322\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.246 | top1-e-train: 0.563, top5-e-train: 0.240 | top1-e-test: 0.571, top5-e-test: 0.253\n",
            "[Epoch   5], lr: 0.10000, Loss: 2.072 | top1-e-train: 0.541, top5-e-train: 0.221 | top1-e-test: 0.560, top5-e-test: 0.247\n",
            "[Epoch   6], lr: 0.10000, Loss: 1.988 | top1-e-train: 0.608, top5-e-train: 0.324 | top1-e-test: 0.620, top5-e-test: 0.346\n",
            "[Epoch   7], lr: 0.10000, Loss: 1.871 | top1-e-train: 0.480, top5-e-train: 0.175 | top1-e-test: 0.519, top5-e-test: 0.215\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.733 | top1-e-train: 0.581, top5-e-train: 0.269 | top1-e-test: 0.592, top5-e-test: 0.294\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.654 | top1-e-train: 0.444, top5-e-train: 0.150 | top1-e-test: 0.504, top5-e-test: 0.206\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.543 | top1-e-train: 0.403, top5-e-train: 0.125 | top1-e-test: 0.481, top5-e-test: 0.192\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.421 | top1-e-train: 0.390, top5-e-train: 0.116 | top1-e-test: 0.475, top5-e-test: 0.186\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.333 | top1-e-train: 0.376, top5-e-train: 0.108 | top1-e-test: 0.470, top5-e-test: 0.193\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.246 | top1-e-train: 0.371, top5-e-train: 0.098 | top1-e-test: 0.486, top5-e-test: 0.187\n",
            "[Epoch  14], lr: 0.10000, Loss: 1.175 | top1-e-train: 0.318, top5-e-train: 0.070 | top1-e-test: 0.448, top5-e-test: 0.163\n",
            "[Epoch  15], lr: 0.10000, Loss: 1.100 | top1-e-train: 0.287, top5-e-train: 0.059 | top1-e-test: 0.446, top5-e-test: 0.163\n",
            "[Epoch  16], lr: 0.10000, Loss: 1.013 | top1-e-train: 0.274, top5-e-train: 0.053 | top1-e-test: 0.441, top5-e-test: 0.162\n",
            "[Epoch  17], lr: 0.10000, Loss: 0.947 | top1-e-train: 0.259, top5-e-train: 0.047 | top1-e-test: 0.443, top5-e-test: 0.165\n",
            "[Epoch  18], lr: 0.10000, Loss: 0.881 | top1-e-train: 0.230, top5-e-train: 0.038 | top1-e-test: 0.427, top5-e-test: 0.161\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.807 | top1-e-train: 0.203, top5-e-train: 0.029 | top1-e-test: 0.431, top5-e-test: 0.161\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.739 | top1-e-train: 0.221, top5-e-train: 0.031 | top1-e-test: 0.447, top5-e-test: 0.170\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.677 | top1-e-train: 0.186, top5-e-train: 0.022 | top1-e-test: 0.438, top5-e-test: 0.163\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.634 | top1-e-train: 0.154, top5-e-train: 0.016 | top1-e-test: 0.426, top5-e-test: 0.160\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.562 | top1-e-train: 0.140, top5-e-train: 0.011 | top1-e-test: 0.427, top5-e-test: 0.165\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.508 | top1-e-train: 0.150, top5-e-train: 0.015 | top1-e-test: 0.437, top5-e-test: 0.172\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.461 | top1-e-train: 0.125, top5-e-train: 0.009 | top1-e-test: 0.428, top5-e-test: 0.159\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.419 | top1-e-train: 0.109, top5-e-train: 0.007 | top1-e-test: 0.425, top5-e-test: 0.162\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.377 | top1-e-train: 0.090, top5-e-train: 0.004 | top1-e-test: 0.419, top5-e-test: 0.164\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.333 | top1-e-train: 0.087, top5-e-train: 0.006 | top1-e-test: 0.422, top5-e-test: 0.161\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.167 | top1-e-train: 0.027, top5-e-train: 0.001 | top1-e-test: 0.390, top5-e-test: 0.144\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.107 | top1-e-train: 0.021, top5-e-train: 0.001 | top1-e-test: 0.385, top5-e-test: 0.144\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.090 | top1-e-train: 0.018, top5-e-train: 0.001 | top1-e-test: 0.386, top5-e-test: 0.143\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.075 | top1-e-train: 0.013, top5-e-train: 0.000 | top1-e-test: 0.385, top5-e-test: 0.141\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.066 | top1-e-train: 0.012, top5-e-train: 0.000 | top1-e-test: 0.384, top5-e-test: 0.141\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.060 | top1-e-train: 0.010, top5-e-train: 0.000 | top1-e-test: 0.385, top5-e-test: 0.141\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.055 | top1-e-train: 0.010, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.140\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.051 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.384, top5-e-test: 0.142\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.046 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.141\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.043 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.143\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.040 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.139\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.006, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.140\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.035 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.141\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.032 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.384, top5-e-test: 0.141\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.032 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.141\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.029 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.385, top5-e-test: 0.140\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.030 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.140\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.028 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.140\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.026 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.381, top5-e-test: 0.139\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.381, top5-e-test: 0.140\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.140\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.139\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.023 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.381, top5-e-test: 0.141\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.021 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.020 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.139\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.019 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.142\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.018 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.138\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.018 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.383, top5-e-test: 0.140\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.016 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.140\n",
            "[Epoch  59], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  60], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.141\n",
            "[Epoch  61], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  62], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  63], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  64], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  65], lr: 0.00100, Loss: 0.016 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  66], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  67], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.138\n",
            "[Epoch  68], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.381, top5-e-test: 0.139\n",
            "[Epoch  69], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.139\n",
            "[Epoch  70], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  71], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.139\n",
            "[Epoch  72], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.139\n",
            "[Epoch  73], lr: 0.00100, Loss: 0.015 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.138\n",
            "[Epoch  74], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  75], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.139\n",
            "[Epoch  76], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  77], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  78], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.137\n",
            "[Epoch  79], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.381, top5-e-test: 0.139\n",
            "[Epoch  80], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  81], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  82], lr: 0.00100, Loss: 0.014 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  83], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  84], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.139\n",
            "[Epoch  85], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.382, top5-e-test: 0.139\n",
            "[Epoch  86], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.137\n",
            "[Epoch  87], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.138\n",
            "[Epoch  88], lr: 0.00100, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  89], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  90], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.140\n",
            "[Epoch  91], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.381, top5-e-test: 0.139\n",
            "[Epoch  92], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.138\n",
            "[Epoch  93], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  94], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  95], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.139\n",
            "[Epoch  96], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.380, top5-e-test: 0.138\n",
            "[Epoch  97], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.002, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.137\n",
            "[Epoch  98], lr: 0.00010, Loss: 0.013 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.379, top5-e-test: 0.137\n",
            "[Epoch  99], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.377, top5-e-test: 0.137\n",
            "[Epoch 100], lr: 0.00010, Loss: 0.012 | top1-e-train: 0.001, top5-e-train: 0.000 | top1-e-test: 0.378, top5-e-test: 0.138\n",
            "--------- Finish Training --------\n",
            "Model:  cbam_resnet34_c\n",
            "Top1E:  0.377300024033\n",
            "Top5E:  0.136900007725\n",
            "\n",
            "\n",
            "e1_train:  [0.8306400179862976, 0.7369400262832642, 0.7022800445556641, 0.6490800380706787, 0.5634199976921082, 0.5414000153541565, 0.607699990272522, 0.47996002435684204, 0.5810600519180298, 0.44440001249313354, 0.4034000039100647, 0.3895000219345093, 0.37626004219055176, 0.3705199956893921, 0.3184000253677368, 0.2869400382041931, 0.27438002824783325, 0.25874000787734985, 0.2295600175857544, 0.20311999320983887, 0.2210400104522705, 0.1857200264930725, 0.1544000506401062, 0.13996005058288574, 0.14956003427505493, 0.12516003847122192, 0.10860002040863037, 0.09030002355575562, 0.08698004484176636, 0.02704000473022461, 0.021120011806488037, 0.017820000648498535, 0.01296001672744751, 0.012199997901916504, 0.009600043296813965, 0.009760022163391113, 0.008320033550262451, 0.007899999618530273, 0.007220029830932617, 0.006300032138824463, 0.006300032138824463, 0.005360007286071777, 0.005280017852783203, 0.004860043525695801, 0.004519999027252197, 0.0042400360107421875, 0.0037400126457214355, 0.004980027675628662, 0.0040000081062316895, 0.003760039806365967, 0.003840029239654541, 0.003280043601989746, 0.0037200450897216797, 0.003040015697479248, 0.0023800134658813477, 0.002460002899169922, 0.0019600391387939453, 0.003040015697479248, 0.0031200051307678223, 0.002160012722015381, 0.003020048141479492, 0.0021200180053710938, 0.0028800368309020996, 0.002240002155303955, 0.0020400285720825195, 0.0019200444221496582, 0.0019200444221496582, 0.0023800134658813477, 0.002460002899169922, 0.0022600293159484863, 0.001840054988861084, 0.002780020236968994, 0.001880049705505371, 0.001640021800994873, 0.0019600391387939453, 0.0027199983596801758, 0.0017800331115722656, 0.0019600391387939453, 0.0017600059509277344, 0.001980006694793701, 0.001940011978149414, 0.0025600194931030273, 0.002160012722015381, 0.0016800165176391602, 0.001600027084350586, 0.0017200112342834473, 0.0014400482177734375, 0.0015600323677062988, 0.0017600059509277344, 0.0012400150299072266, 0.0017200112342834473, 0.0017000436782836914, 0.0020800232887268066, 0.0012400150299072266, 0.001900017261505127, 0.0017600059509277344, 0.001640021800994873, 0.0020800232887268066, 0.0009800195693969727, 0.0012400150299072266, 0.0014200210571289062]\n",
            "e5_train:  [0.5532799959182739, 0.41746002435684204, 0.39928001165390015, 0.31880003213882446, 0.23966002464294434, 0.22102004289627075, 0.32359999418258667, 0.17506003379821777, 0.26930004358291626, 0.15036004781723022, 0.12496000528335571, 0.11555999517440796, 0.10758000612258911, 0.09842002391815186, 0.06972002983093262, 0.05854004621505737, 0.0529400110244751, 0.047380030155181885, 0.037600040435791016, 0.029000043869018555, 0.03130000829696655, 0.02192002534866333, 0.016019999980926514, 0.011340022087097168, 0.015020012855529785, 0.00896000862121582, 0.007400035858154297, 0.004340052604675293, 0.005659997463226318, 0.0005800127983093262, 0.0008800029754638672, 0.0010600090026855469, 0.00016003847122192383, 0.0002200007438659668, 0.00016003847122192383, 0.0001800060272216797, 0.00012004375457763672, 0.00020003318786621094, 0.0002200007438659668, 0.00010001659393310547, 0.00016003847122192383, 4.00543212890625e-05, 2.002716064453125e-05, 0.00010001659393310547, 8.004903793334961e-05, 8.004903793334961e-05, 0.0, 0.0003800392150878906, 0.0001800060272216797, 0.00010001659393310547, 0.00010001659393310547, 8.004903793334961e-05, 0.0002599954605102539, 6.002187728881836e-05, 6.002187728881836e-05, 0.0, 0.0, 0.00014001131057739258, 0.0002599954605102539, 0.0, 0.00024002790451049805, 0.0, 0.0003000497817993164, 0.0, 4.00543212890625e-05, 2.002716064453125e-05, 0.0, 0.00014001131057739258, 0.00020003318786621094, 4.00543212890625e-05, 4.00543212890625e-05, 0.00020003318786621094, 2.002716064453125e-05, 2.002716064453125e-05, 6.002187728881836e-05, 0.00016003847122192383, 2.002716064453125e-05, 8.004903793334961e-05, 0.0, 0.0, 8.004903793334961e-05, 0.0001800060272216797, 4.00543212890625e-05, 8.004903793334961e-05, 2.002716064453125e-05, 2.002716064453125e-05, 0.0, 4.00543212890625e-05, 8.004903793334961e-05, 0.0, 0.0, 0.0, 6.002187728881836e-05, 0.0, 8.004903793334961e-05, 0.0, 2.002716064453125e-05, 8.004903793334961e-05, 0.0, 0.0, 2.002716064453125e-05]\n",
            "\n",
            "\n",
            "e1_test:  [0.8230000138282776, 0.7351000308990479, 0.6829999685287476, 0.652899980545044, 0.570900022983551, 0.5598000288009644, 0.6198999881744385, 0.5190000534057617, 0.5918999910354614, 0.5044000148773193, 0.4808000326156616, 0.47540003061294556, 0.4702000021934509, 0.4864000082015991, 0.4480000138282776, 0.446399986743927, 0.44060003757476807, 0.4431000351905823, 0.42730003595352173, 0.4311000108718872, 0.4474000334739685, 0.43790000677108765, 0.42570000886917114, 0.42669999599456787, 0.43730002641677856, 0.4280000329017639, 0.42510002851486206, 0.41940003633499146, 0.4223000407218933, 0.39030003547668457, 0.38520002365112305, 0.38600003719329834, 0.38510000705718994, 0.38359999656677246, 0.38510000705718994, 0.3830000162124634, 0.38370001316070557, 0.3815000057220459, 0.38260000944137573, 0.3831999897956848, 0.38270002603530884, 0.38270002603530884, 0.38429999351501465, 0.3831000328063965, 0.38450002670288086, 0.3822000026702881, 0.37929999828338623, 0.3806000351905823, 0.37860000133514404, 0.3808000087738037, 0.3824000358581543, 0.382099986076355, 0.38050001859664917, 0.3797000050544739, 0.37800002098083496, 0.38179999589920044, 0.3815000057220459, 0.3833000063896179, 0.38200002908706665, 0.3790000081062317, 0.3822000026702881, 0.38040000200271606, 0.3799999952316284, 0.3797000050544739, 0.38040000200271606, 0.3799999952316284, 0.379800021648407, 0.3791000247001648, 0.3806999921798706, 0.381600022315979, 0.3799000382423401, 0.3824000358581543, 0.37959998846054077, 0.3792000412940979, 0.38030004501342773, 0.3822000026702881, 0.37929999828338623, 0.3797000050544739, 0.3797000050544739, 0.38109999895095825, 0.38040000200271606, 0.3797000050544739, 0.3790000081062317, 0.3791000247001648, 0.3815000057220459, 0.38200002908706665, 0.3784000277519226, 0.3781999945640564, 0.3801000118255615, 0.37880003452301025, 0.38020002841949463, 0.38120001554489136, 0.37779998779296875, 0.37929999828338623, 0.3799000382423401, 0.3788999915122986, 0.3797000050544739, 0.3783000111579895, 0.37929999828338623, 0.3773000240325928, 0.37779998779296875]\n",
            "e5_test:  [0.5439000129699707, 0.41589999198913574, 0.3799000382423401, 0.32179999351501465, 0.25310003757476807, 0.24720001220703125, 0.34619998931884766, 0.21530002355575562, 0.29370003938674927, 0.20610004663467407, 0.1915000081062317, 0.18580001592636108, 0.19260001182556152, 0.18650001287460327, 0.163100004196167, 0.16260004043579102, 0.16170001029968262, 0.16530001163482666, 0.16120004653930664, 0.16060000658035278, 0.17010003328323364, 0.16339999437332153, 0.15960001945495605, 0.16460001468658447, 0.17170000076293945, 0.15880000591278076, 0.16220003366470337, 0.16430002450942993, 0.16110002994537354, 0.1444000005722046, 0.1438000202178955, 0.14300000667572021, 0.14100003242492676, 0.14079999923706055, 0.14149999618530273, 0.14030003547668457, 0.14240002632141113, 0.1414000391960144, 0.14259999990463257, 0.1388000249862671, 0.13950002193450928, 0.140500009059906, 0.14079999923706055, 0.14070004224777222, 0.13990002870559692, 0.13980001211166382, 0.13950002193450928, 0.13920003175735474, 0.1389000415802002, 0.13990002870559692, 0.1396999955177307, 0.1389000415802002, 0.14090001583099365, 0.1388000249862671, 0.13899999856948853, 0.14160001277923584, 0.13840001821517944, 0.14000004529953003, 0.13950002193450928, 0.13870000839233398, 0.140500009059906, 0.13910001516342163, 0.13940000534057617, 0.1388000249862671, 0.13920003175735474, 0.13920003175735474, 0.1380000114440918, 0.13840001821517944, 0.13850003480911255, 0.13870000839233398, 0.13860005140304565, 0.13860005140304565, 0.1389000415802002, 0.1380000114440918, 0.13760000467300415, 0.13930004835128784, 0.13930004835128784, 0.13780003786087036, 0.1373000144958496, 0.13870000839233398, 0.13840001821517944, 0.13780003786087036, 0.13920003175735474, 0.1389000415802002, 0.13920003175735474, 0.13870000839233398, 0.1373000144958496, 0.1378999948501587, 0.13750004768371582, 0.13920003175735474, 0.13960003852844238, 0.13850003480911255, 0.138200044631958, 0.13920003175735474, 0.13750004768371582, 0.13899999856948853, 0.1380000114440918, 0.1371999979019165, 0.13690000772476196, 0.13740003108978271, 0.13760000467300415]\n",
            "\n",
            "\n",
            "TIME:  7810.55566716\n",
            "--------------- DONE!!! ----------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}