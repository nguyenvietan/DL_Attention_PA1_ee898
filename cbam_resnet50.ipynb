{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cbam_resnet50.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenvietan/DL_Attention_PA1_ee898/blob/master/cbam_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CePGsRcqojbW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1176
        },
        "outputId": "bcf45c9e-f8ac-43d7-bb72-e3436a05ed21"
      },
      "source": [
        "!python train.py --arch cbam_resnet50 --epoch 100\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(arch='cbam_resnet50', batch_size=128, epoch=100, learning_rate=0.1)\n",
            "Model:  cbam_resnet50\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch   0], lr: 0.10000, Loss: 4.236 | top1-e-train: 0.872, top5-e-train: 0.627 | top1-e-test: 0.863, top5-e-test: 0.613\n",
            "[Epoch   1], lr: 0.10000, Loss: 3.406 | top1-e-train: 0.779, top5-e-train: 0.487 | top1-e-test: 0.769, top5-e-test: 0.483\n",
            "[Epoch   2], lr: 0.10000, Loss: 3.146 | top1-e-train: 0.730, top5-e-train: 0.419 | top1-e-test: 0.731, top5-e-test: 0.412\n",
            "[Epoch   3], lr: 0.10000, Loss: 2.789 | top1-e-train: 0.681, top5-e-train: 0.360 | top1-e-test: 0.681, top5-e-test: 0.361\n",
            "[Epoch   4], lr: 0.10000, Loss: 2.530 | top1-e-train: 0.612, top5-e-train: 0.287 | top1-e-test: 0.622, top5-e-test: 0.304\n",
            "[Epoch   5], lr: 0.10000, Loss: 2.319 | top1-e-train: 0.591, top5-e-train: 0.261 | top1-e-test: 0.607, top5-e-test: 0.287\n",
            "[Epoch   6], lr: 0.10000, Loss: 2.159 | top1-e-train: 0.558, top5-e-train: 0.236 | top1-e-test: 0.584, top5-e-test: 0.268\n",
            "[Epoch   7], lr: 0.10000, Loss: 2.007 | top1-e-train: 0.523, top5-e-train: 0.205 | top1-e-test: 0.559, top5-e-test: 0.248\n",
            "[Epoch   8], lr: 0.10000, Loss: 1.867 | top1-e-train: 0.483, top5-e-train: 0.177 | top1-e-test: 0.536, top5-e-test: 0.234\n",
            "[Epoch   9], lr: 0.10000, Loss: 1.754 | top1-e-train: 0.456, top5-e-train: 0.155 | top1-e-test: 0.524, top5-e-test: 0.215\n",
            "[Epoch  10], lr: 0.10000, Loss: 1.650 | top1-e-train: 0.423, top5-e-train: 0.136 | top1-e-test: 0.510, top5-e-test: 0.212\n",
            "[Epoch  11], lr: 0.10000, Loss: 1.538 | top1-e-train: 0.401, top5-e-train: 0.118 | top1-e-test: 0.501, top5-e-test: 0.203\n",
            "[Epoch  12], lr: 0.10000, Loss: 1.437 | top1-e-train: 0.379, top5-e-train: 0.104 | top1-e-test: 0.496, top5-e-test: 0.199\n",
            "[Epoch  13], lr: 0.10000, Loss: 1.340 | top1-e-train: 0.347, top5-e-train: 0.087 | top1-e-test: 0.477, top5-e-test: 0.193\n",
            "[Epoch  14], lr: 0.10000, Loss: 1.241 | top1-e-train: 0.317, top5-e-train: 0.072 | top1-e-test: 0.478, top5-e-test: 0.192\n",
            "[Epoch  15], lr: 0.10000, Loss: 1.157 | top1-e-train: 0.299, top5-e-train: 0.065 | top1-e-test: 0.466, top5-e-test: 0.186\n",
            "[Epoch  16], lr: 0.10000, Loss: 1.074 | top1-e-train: 0.275, top5-e-train: 0.053 | top1-e-test: 0.463, top5-e-test: 0.182\n",
            "[Epoch  17], lr: 0.10000, Loss: 0.994 | top1-e-train: 0.251, top5-e-train: 0.043 | top1-e-test: 0.461, top5-e-test: 0.177\n",
            "[Epoch  18], lr: 0.10000, Loss: 0.908 | top1-e-train: 0.240, top5-e-train: 0.039 | top1-e-test: 0.460, top5-e-test: 0.186\n",
            "[Epoch  19], lr: 0.10000, Loss: 0.829 | top1-e-train: 0.231, top5-e-train: 0.034 | top1-e-test: 0.462, top5-e-test: 0.184\n",
            "[Epoch  20], lr: 0.10000, Loss: 0.758 | top1-e-train: 0.202, top5-e-train: 0.025 | top1-e-test: 0.469, top5-e-test: 0.183\n",
            "[Epoch  21], lr: 0.10000, Loss: 0.686 | top1-e-train: 0.182, top5-e-train: 0.022 | top1-e-test: 0.473, top5-e-test: 0.186\n",
            "[Epoch  22], lr: 0.10000, Loss: 0.637 | top1-e-train: 0.168, top5-e-train: 0.018 | top1-e-test: 0.469, top5-e-test: 0.185\n",
            "[Epoch  23], lr: 0.10000, Loss: 0.561 | top1-e-train: 0.141, top5-e-train: 0.014 | top1-e-test: 0.457, top5-e-test: 0.183\n",
            "[Epoch  24], lr: 0.10000, Loss: 0.521 | top1-e-train: 0.121, top5-e-train: 0.009 | top1-e-test: 0.458, top5-e-test: 0.178\n",
            "[Epoch  25], lr: 0.10000, Loss: 0.459 | top1-e-train: 0.111, top5-e-train: 0.007 | top1-e-test: 0.447, top5-e-test: 0.180\n",
            "[Epoch  26], lr: 0.10000, Loss: 0.403 | top1-e-train: 0.100, top5-e-train: 0.005 | top1-e-test: 0.446, top5-e-test: 0.181\n",
            "[Epoch  27], lr: 0.10000, Loss: 0.373 | top1-e-train: 0.086, top5-e-train: 0.004 | top1-e-test: 0.443, top5-e-test: 0.178\n",
            "[Epoch  28], lr: 0.10000, Loss: 0.331 | top1-e-train: 0.092, top5-e-train: 0.004 | top1-e-test: 0.455, top5-e-test: 0.188\n",
            "[Epoch  29], lr: 0.01000, Loss: 0.158 | top1-e-train: 0.025, top5-e-train: 0.001 | top1-e-test: 0.416, top5-e-test: 0.165\n",
            "[Epoch  30], lr: 0.01000, Loss: 0.107 | top1-e-train: 0.019, top5-e-train: 0.000 | top1-e-test: 0.415, top5-e-test: 0.161\n",
            "[Epoch  31], lr: 0.01000, Loss: 0.087 | top1-e-train: 0.015, top5-e-train: 0.000 | top1-e-test: 0.412, top5-e-test: 0.160\n",
            "[Epoch  32], lr: 0.01000, Loss: 0.073 | top1-e-train: 0.015, top5-e-train: 0.000 | top1-e-test: 0.413, top5-e-test: 0.161\n",
            "[Epoch  33], lr: 0.01000, Loss: 0.066 | top1-e-train: 0.012, top5-e-train: 0.000 | top1-e-test: 0.411, top5-e-test: 0.160\n",
            "[Epoch  34], lr: 0.01000, Loss: 0.063 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.414, top5-e-test: 0.160\n",
            "[Epoch  35], lr: 0.01000, Loss: 0.057 | top1-e-train: 0.011, top5-e-train: 0.000 | top1-e-test: 0.413, top5-e-test: 0.162\n",
            "[Epoch  36], lr: 0.01000, Loss: 0.053 | top1-e-train: 0.009, top5-e-train: 0.000 | top1-e-test: 0.413, top5-e-test: 0.161\n",
            "[Epoch  37], lr: 0.01000, Loss: 0.048 | top1-e-train: 0.009, top5-e-train: 0.000 | top1-e-test: 0.411, top5-e-test: 0.162\n",
            "[Epoch  38], lr: 0.01000, Loss: 0.046 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.412, top5-e-test: 0.161\n",
            "[Epoch  39], lr: 0.01000, Loss: 0.044 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.411, top5-e-test: 0.162\n",
            "[Epoch  40], lr: 0.01000, Loss: 0.041 | top1-e-train: 0.009, top5-e-train: 0.000 | top1-e-test: 0.410, top5-e-test: 0.163\n",
            "[Epoch  41], lr: 0.01000, Loss: 0.039 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.410, top5-e-test: 0.160\n",
            "[Epoch  42], lr: 0.01000, Loss: 0.035 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.410, top5-e-test: 0.161\n",
            "[Epoch  43], lr: 0.01000, Loss: 0.035 | top1-e-train: 0.007, top5-e-train: 0.001 | top1-e-test: 0.410, top5-e-test: 0.160\n",
            "[Epoch  44], lr: 0.01000, Loss: 0.032 | top1-e-train: 0.007, top5-e-train: 0.000 | top1-e-test: 0.409, top5-e-test: 0.161\n",
            "[Epoch  45], lr: 0.01000, Loss: 0.033 | top1-e-train: 0.008, top5-e-train: 0.000 | top1-e-test: 0.414, top5-e-test: 0.163\n",
            "[Epoch  46], lr: 0.01000, Loss: 0.037 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.410, top5-e-test: 0.160\n",
            "[Epoch  47], lr: 0.01000, Loss: 0.031 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.410, top5-e-test: 0.160\n",
            "[Epoch  48], lr: 0.01000, Loss: 0.029 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.409, top5-e-test: 0.161\n",
            "[Epoch  49], lr: 0.01000, Loss: 0.027 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.408, top5-e-test: 0.161\n",
            "[Epoch  50], lr: 0.01000, Loss: 0.026 | top1-e-train: 0.005, top5-e-train: 0.000 | top1-e-test: 0.409, top5-e-test: 0.162\n",
            "[Epoch  51], lr: 0.01000, Loss: 0.025 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.413, top5-e-test: 0.162\n",
            "[Epoch  52], lr: 0.01000, Loss: 0.025 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.409, top5-e-test: 0.163\n",
            "[Epoch  53], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.411, top5-e-test: 0.162\n",
            "[Epoch  54], lr: 0.01000, Loss: 0.024 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.409, top5-e-test: 0.161\n",
            "[Epoch  55], lr: 0.01000, Loss: 0.022 | top1-e-train: 0.005, top5-e-train: 0.001 | top1-e-test: 0.412, top5-e-test: 0.161\n",
            "[Epoch  56], lr: 0.01000, Loss: 0.021 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.412, top5-e-test: 0.163\n",
            "[Epoch  57], lr: 0.01000, Loss: 0.020 | top1-e-train: 0.004, top5-e-train: 0.000 | top1-e-test: 0.410, top5-e-test: 0.162\n",
            "[Epoch  58], lr: 0.01000, Loss: 0.021 | top1-e-train: 0.003, top5-e-train: 0.000 | top1-e-test: 0.409, top5-e-test: 0.161\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 135, in <module>\n",
            "    for data in trainloader:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}